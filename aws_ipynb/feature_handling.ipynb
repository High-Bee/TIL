{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "iris = datasets.load_iris() #데이터를 로드\n",
    "features = iris.data # 특성과 타깃을 만듭니다\n",
    "target = iris.target\n",
    "thresholder = VarianceThreshold(threshold=.6) # 기준값을 만듭니다.\n",
    "features_high_variance = thresholder.fit_transform(features) # 기준값보다 높은 특성을 선택합니다.\n",
    "features_high_variance[0:3] # 선택한 특성을 확인\n",
    "thresholder.variances_ # 분산 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() # 특성 행렬을 표준화합니다.\n",
    "features_std = scaler.fit_transform(features)\n",
    "selector = VarianceThreshold() # 각 특성의 분산을 계산합니다.\n",
    "selector.fit(features_std).variances_ # 특성을 표준화하면 평균이 0으로 모든 분산이 1로 맞추어 짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4],\n",
       "       [4.9, 1.4],\n",
       "       [4.7, 1.3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_high_variance[0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16, 0.16, 0.24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "features = [[0, 1, 0], # 예제 특성 행렬\n",
    "            [0, 1, 1], # 특성 0: 80%가 클래스 0\n",
    "            [0, 1, 0], # 특성 1: 80%가 클래스 1\n",
    "            [0, 1, 1], # 특성 2: 60%가 클래스 0, 40%는 클래스 1\n",
    "            [1, 0, 0]]\n",
    "# 분산을 기준으로 선택합니다.\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)\n",
    "thresholder.variances_\n",
    "\n",
    "np.var(features, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계가 큰 두 개의 특성을 가진 특성 행렬을 만듭니다.\n",
    "features = np.array([[1, 1, 1], [2, 2, 0], [3, 3, 1], [4, 4, 0], [5, 5, 1],\n",
    "[6, 6, 0], [7, 7, 1], [8, 7, 0], [9, 7, 1]])\n",
    "dataframe = pd.DataFrame(features) # 특성 행렬을 DataFrame으로 변환\n",
    "corr_matrix = dataframe.corr().abs() # 상관관계 행렬을 만듭니다.\n",
    "# 상관관계 행렬의 상삼각(upper triangle) 행렬을 선택합니다.\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# 상관 계수가 0.95보다 큰 특성 열의 인덱스를 찾습니다.\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2\n",
       "0 NaN  0.976103  0.000000\n",
       "1 NaN       NaN  0.034503\n",
       "2 NaN       NaN       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.97610336,  0.        ],\n",
       "       [ 0.97610336,  1.        , -0.03450328],\n",
       "       [ 0.        , -0.03450328,  1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(features, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "iris = load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "features = features.astype(int) # 범주형 데이터를 정수형으로 변환\n",
    "chi2_selector = SelectKBest(chi2, k=2) # 카이제곱 통계값이 가장 큰 특성 두 개를 선택\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 2\n",
      "원본 특성 개수: 4\n",
      "줄어든 특성 개수: 3\n"
     ]
    }
   ],
   "source": [
    "# F-값이 가장 높은 특성 두 개를 선택합니다.\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 확인\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])\n",
    "# 특정 특성 개수를 선택하는 대신 Selectpercentile를 사용하여 특성의 상위 n 퍼센트를 선택할 수 있습니다.\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# 가장 큰 F-값의 상위 75% 특성을 선택합니다.\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "print(\"원본 특성 개수:\", features.shape[1]) # 결과 선택\n",
    "print(\"줄어든 특성 개수:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.28712871,   5.02267003, 133.06854839,  74.27906977])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target\n",
    "#특성 행렬의 차원을 (3, 50, 4)로 바꾸어 클래스별 합을 구합니다.\n",
    "observed = np.sum(features.reshape(3, 50, 4), axis=1)\n",
    "observed\n",
    "#특성 타깃과 전혀 관계없다면 기대 빈도는 전체 합을 클래스 개수 3으로 나눈 값이 됩니다.\n",
    "expected = features.sum(axis=0) / 3\n",
    "expected\n",
    "#카이제곱 공식에 위헤서 구한 observed와 expected를 대입합니다.\n",
    "np.sum((observed - expected)**2 / expected, axis=0)\n",
    "#카이제곱 값이 큰 세 번째, 네 번째 특성이 선택됩니다. chi2_selector객체의 scores_속성에 저장\n",
    "chi2_selector.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[230 152  50   0]\n",
      " [274 116 191  50]\n",
      " [304 129 255  79]] \n",
      " [269.33333333 132.33333333 165.33333333  43.        ]\n"
     ]
    }
   ],
   "source": [
    "print(observed, '\\n',expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  81.19776715   33.71497585 1160.00645624  385.48275862]\n",
      "[  81.19776715   33.71497585 1160.00645624  385.48275862]\n"
     ]
    }
   ],
   "source": [
    "#ANOVA 직접 계산\n",
    "##전체 평균과 클래스 평균을 계산\n",
    "total_mean = np.mean(features, axis=0)\n",
    "total_mean\n",
    "class_mean = np.mean(features.reshape(3, 50, 4), axis=1)\n",
    "class_mean\n",
    "#ss_total 계산\n",
    "ss_between = np.sum(50 * (class_mean - total_mean)**2, axis=0)\n",
    "ss_between\n",
    "ss_total = np.sum((features - total_mean)**2, axis=0)\n",
    "ss_total\n",
    "#ss_beteen과 ss_tatal을 F-값 공식에 대입\n",
    "f = (ss_between/(3-1)) / ((ss_total-ss_between)/(150-3))\n",
    "print(f)\n",
    "print(fvalue_selector.scores_) #F-값 scores_속성에서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799,  0.7031277 ,  0.70243828, -0.34606121],\n",
       "       [-1.07500204,  2.56148527, -0.07152579, -1.8392567 ],\n",
       "       [ 1.37940721, -1.77039484, -0.00791373, -0.90016708],\n",
       "       ...,\n",
       "       [-0.80331656, -1.60648007, -1.3494921 , -1.28329706],\n",
       "       [ 0.39508844, -1.34564911, -0.55243048,  0.85012142],\n",
       "       [-0.55383035,  0.82880112, -0.5175125 ,  0.27741159]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 특성 행렬과 타깃 벡터를 생성합니다.\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "n_features = 100,\n",
    "n_informative = 2,\n",
    "random_state = 1)\n",
    "# 선형 회귀 모델을 만듭니다.\n",
    "ols = linear_model.LinearRegression()\n",
    "# 재귀적으로 특성을 제거합니다.\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.n_features_ # 최선의 특성 개수\n",
    "rfecv.support_ # 선택된 특성이 표시된 불리언 마스크\n",
    "rfecv.ranking_ # 특성의 순위: 최고(1)에서 최악(96)까지\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(estimator=ols, n_features_to_select=4)\n",
    "rfe.fit(features, target)\n",
    "rfe.transform(features)\n",
    "# rfe객체가 선택한 특성이 rfecv 객체가 선택한 특성과 동일한지 확인하기 위해 불리언 마스크를 비교\n",
    "np.all(rfe.support_ == rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits = datasets.load_digits() # 데이터셋 로드\n",
    "features = digits.data # 특성 행렬을 만듭니다.\n",
    "target = digits.target # 타깃 벡터를 만듭니다.\n",
    "standardizer = StandardScaler() # 표준화 객체를 만듭니다.\n",
    "logit = LogisticRegression() # # 로지스틱 회귀 객체를 만듭니다\n",
    "\n",
    "# 표준화한 다음 로지스틱 회귀를 실행하는 파이프라인을 만듭니다.\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1) # k-폴드 교차검증을 만듭니다. (10 개의 폴드를 만듬)\n",
    "\n",
    "# k-폴드 교차검증을 수행합니다.\n",
    "cv_results = cross_val_score(pipeline, features, target, cv=kf, # 교차 검증 기법\n",
    "                            scoring=\"accuracy\", # 평가 지표\n",
    "                            n_jobs=-1) # 모든 CPU 코어 사용\n",
    "\n",
    "cv_results.mean() # 평균을 계산\n",
    "cv_results ## 10개 폴드의 점수를 모두 확인(평가 점수는 cv_results에 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97222222, 0.97777778, 0.95555556, 0.95      , 0.95555556,\n",
       "       0.98333333, 0.97777778, 0.96648045, 0.96089385, 0.94972067])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 훈련 세트와 테스트 세트를 만듭니다.\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split( features, target, test_size=0.1, random_state=1)\n",
    "standardizer.fit(features_train) # 훈련 세트로 standardizer의 fit 메서드를 호출\n",
    "\n",
    "# 훈련 세트와 테스트 세트에 모두 적용합니다.\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n",
    "pipeline = make_pipeline(standardizer, logit) # 파이프라인을 만듭니다.\n",
    "\n",
    "# k-폴드 교차 검증 수행\n",
    "cv_results = cross_val_score(pipeline, # 파이프라인\n",
    "                            features, # 특성 행렬\n",
    "                            target, # 타깃 벡터\n",
    "                            cv=kf, # 교차검증\n",
    "                            scoring=\"accuracy\", # 평가 지표\n",
    "                            n_jobs=-1) # 모든 CPU 코어 사용b\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "        5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "        3.59381366e+03, 1.00000000e+04]), 'penalty': ['l1', 'l2']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#실습 : 로지스틱 회귀에서 C와 규제 페널티 값의 각 조합에 대해 모델을 훈련하고 k-폴드 교차검증으로 평가합니다.\n",
    "#C의 값이 10개이고 규제 페널티는 두 개, 폴드 수는 5입니다. 총 10X2X5=100개의 모델 후보 중에서 가장 좋은 것을\n",
    "#선택합니다.\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "logistic = linear_model.LogisticRegression() # 로지스틱 회귀 모델 객체 생성\n",
    "penalty = ['l1', 'l2'] # 페널티(penalty) 하이퍼파라미터 값의 후보를 만듭니다.\n",
    "C = np.logspace(0, 4, 10) # 규제 하이퍼파라미터 값의 후보 범위를 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 페널티: l1\n",
      "가장 좋은 C 값: 7.742636826811269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=1) # 그리드 서치 객체 생성\n",
    "best_model = gridsearch.fit(features, target) # 그리드 서치 수행 .\n",
    "np.logspace(0, 4, 10)\n",
    "# 최선의 하이퍼파라미터를 확인합니다.\n",
    "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])\n",
    "best_model.predict(features) # 타깃 벡터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "np.random.seed(0) # 랜덤 시드 설정\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())]) # 파이프라인을 만듭니다.\n",
    "# 후보 학습 알고리즘과 하이퍼파라미터로 딕셔너리를 만듭니다.\n",
    "search_space = [ { \"classifier\": [LogisticRegression()],\n",
    "\"classifier__penalty\": ['l1', 'l2'],\n",
    "\"classifier__C\": np.logspace(0, 4, 10)},\n",
    "{ \"classifier\": [RandomForestClassifier()],\n",
    "\"classifier__n_estimators\": [10, 100, 1000],\n",
    "\"classifier__max_features\": [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 145 out of 145 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=1) # 그리드 서치 객체 생성\n",
    "best_model = gridsearch.fit(features, target) # 그리드 서치를 수행\n",
    "best_model.best_estimator_.get_params()[\"classifier\"] # 최선의 모델을 확인\n",
    "best_model.predict(features) # 타깃 벡터를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.742636826811269, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()[\"classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(0) # 랜덤 시드 설정\n",
    "iris = datasets.load_iris() # 데이터 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# StandardScaler와 PCA를 포함한 전처리 객체를 만듭니다.\n",
    "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "# 파이프라인을 만듭니다.\n",
    "pipe = Pipeline([(\"preprocess\", preprocess), (\"classifier\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보 값을 정의합니다.\n",
    "#최선의 모델을 만드는 주성분이 하나인지 두개, 세 개인지를 탐색하도록 지시합니다.\n",
    "search_space = [{\"preprocess__pca__n_components\": [1, 2, 3],\n",
    "                \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1) # 그리드 서치 객체 생성\n",
    "\n",
    "best_model = clf.fit(features, target) # 그리드 서치 수행\n",
    "\n",
    "best_model.best_estimator_.get_params()['preprocess__pca__n_components'] # 최선의 주성분 개수를 확인\n",
    "clf.best_score_ #GridSearchCV가 수행한 교차검증에서 최상의 점수가 저장되는 속성\n",
    "\n",
    "clf.best_estimator_.named_steps[\"preprocess\"].transform(features[0:1])\n",
    "# memory 매개변수에 전처리 데이터를 임시 저장할 디렉토리 이름을 전달하면 하이퍼파라미터 탐색 과정에서\n",
    "# 중복으로 전처리 과정을 수행하지 않습니다\n",
    "pipe = Pipeline([(\"std\", StandardScaler()),\n",
    "                (\"pca\", PCA()),\n",
    "                (\"classifier\", LogisticRegression())],\n",
    "                memory='cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.64026976,  5.2040413 , -2.48862071]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 후보 값을 정의합니다.\n",
    "search_space = [{\"pca__n_components\": [1, 2, 3],\n",
    "                \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1) # 그리드 서치 객체생성\n",
    "best_model = clf.fit(features, target) # 그리드 서치 수행\n",
    "\n",
    "clf.best_score_\n",
    "\n",
    "clf.best_estimator_.get_params()['pca__n_components'] # 최선의 주성분 개수를 확인\n",
    "\n",
    "clf.best_estimator_.named_steps[\"pca\"].transform(features[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 5112 tasks      | elapsed:   15.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.2 s, sys: 40.4 ms, total: 7.24 s\n",
      "Wall time: 34.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:   34.6s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris() # 데이터를 로드\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "logistic = linear_model.LogisticRegression() # 로지스틱 회귀 모델 객체 생성\n",
    "penalty = [\"l1\", \"l2\"] # 규제 페널티의 후보를 만듭니다.\n",
    "C = np.logspace(0, 4, 1000) # C 값의 후보 범위를 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty) # 하이퍼파라미터 옵션을 만듭니다.\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=1)\n",
    "best_model = gridsearch.fit(features, target)\n",
    "# 하나의 코어만 사용하는 그리드 서치 객체를 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 38.1 ms, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 10000 out of 10000 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=1, verbose=1)\n",
    "best_model = clf.fit(features, target) # 그리드 서치를 수행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
