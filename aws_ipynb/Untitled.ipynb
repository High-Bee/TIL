{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# tf.keras.backend.clear_session() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data load\n",
    "df_origin = pd.read_csv(\"./data/train_idall_et10_row60_col3273_Delunique.csv\")\n",
    "\n",
    "df_x = df_origin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41400, 3273)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 전처리\n",
    "df_x.head()\n",
    "df_x.iloc[:,1:-1].head().shape\n",
    "x_train = df_x.iloc[:,1:-1]\n",
    "x_train = MinMaxScaler().fit_transform(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = pd.get_dummies(df_x[\"label\"])\n",
    "y_train = df_x[\"label\"]\n",
    "# y_train = y_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3273,), name='digits')\n",
    "x = layers.Dense(512, activation='sigmoid', name='dense_1')(inputs)\n",
    "x = layers.Dense(198, activation='sigmoid', name='dense_2')(x)\n",
    "outputs = layers.Dense(198, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              # List of metrics to monitor\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected predictions to have shape (1,) but got array with shape (198,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6d38c993f7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x_train, y_train,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     epochs=3)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected predictions to have shape (1,) but got array with shape (198,)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41400, 3273)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 3273)]            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1676288   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 198)               50886     \n",
      "=================================================================\n",
      "Total params: 1,858,502\n",
      "Trainable params: 1,858,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.utils' has no attribute 'np_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-452c494ad555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.utils' has no attribute 'np_utils'"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "keras.utils.np_utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(3273,), name='digits')\n",
    "x = layers.Dense(512, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(256, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(198, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Train on 41400 samples\n",
      "Epoch 1/360\n",
      "41400/41400 [==============================] - 5s 115us/sample - loss: 4.5150 - categorical_accuracy: 0.1040\n",
      "Epoch 2/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 3.8315 - categorical_accuracy: 0.2344\n",
      "Epoch 3/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 3.2160 - categorical_accuracy: 0.3738\n",
      "Epoch 4/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 2.6495 - categorical_accuracy: 0.4710\n",
      "Epoch 5/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 2.3337 - categorical_accuracy: 0.5163\n",
      "Epoch 6/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 2.1693 - categorical_accuracy: 0.5425\n",
      "Epoch 7/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 2.0703 - categorical_accuracy: 0.5616\n",
      "Epoch 8/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.9986 - categorical_accuracy: 0.5726\n",
      "Epoch 9/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.9627 - categorical_accuracy: 0.5745\n",
      "Epoch 10/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.9289 - categorical_accuracy: 0.5848\n",
      "Epoch 11/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.9169 - categorical_accuracy: 0.5810\n",
      "Epoch 12/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.9999 - categorical_accuracy: 0.5691\n",
      "Epoch 13/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.8429 - categorical_accuracy: 0.5969\n",
      "Epoch 14/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.8490 - categorical_accuracy: 0.5949\n",
      "Epoch 15/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7856 - categorical_accuracy: 0.6050\n",
      "Epoch 16/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.8289 - categorical_accuracy: 0.5968\n",
      "Epoch 17/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 2.5442 - categorical_accuracy: 0.5266\n",
      "Epoch 18/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.8604 - categorical_accuracy: 0.6035\n",
      "Epoch 19/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7875 - categorical_accuracy: 0.6095\n",
      "Epoch 20/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7776 - categorical_accuracy: 0.6081\n",
      "Epoch 21/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7280 - categorical_accuracy: 0.6165\n",
      "Epoch 22/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.7141 - categorical_accuracy: 0.6161\n",
      "Epoch 23/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 2.2017 - categorical_accuracy: 0.5553\n",
      "Epoch 24/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.7651 - categorical_accuracy: 0.6150\n",
      "Epoch 25/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.7319 - categorical_accuracy: 0.6158\n",
      "Epoch 26/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7198 - categorical_accuracy: 0.6172\n",
      "Epoch 27/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6978 - categorical_accuracy: 0.6209\n",
      "Epoch 28/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6674 - categorical_accuracy: 0.6228\n",
      "Epoch 29/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6430 - categorical_accuracy: 0.6270\n",
      "Epoch 30/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6343 - categorical_accuracy: 0.6261\n",
      "Epoch 31/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.7958 - categorical_accuracy: 0.6000\n",
      "Epoch 32/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6328 - categorical_accuracy: 0.6310\n",
      "Epoch 33/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.6091 - categorical_accuracy: 0.6325\n",
      "Epoch 34/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6384 - categorical_accuracy: 0.6275\n",
      "Epoch 35/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.6032 - categorical_accuracy: 0.6311\n",
      "Epoch 36/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5864 - categorical_accuracy: 0.6358\n",
      "Epoch 37/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6067 - categorical_accuracy: 0.6294\n",
      "Epoch 38/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5486 - categorical_accuracy: 0.6377\n",
      "Epoch 39/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7965 - categorical_accuracy: 0.6067\n",
      "Epoch 40/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5596 - categorical_accuracy: 0.6405\n",
      "Epoch 41/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5479 - categorical_accuracy: 0.6396\n",
      "Epoch 42/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5337 - categorical_accuracy: 0.6433\n",
      "Epoch 43/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5255 - categorical_accuracy: 0.6428\n",
      "Epoch 44/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.8867 - categorical_accuracy: 0.5901\n",
      "Epoch 45/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5718 - categorical_accuracy: 0.6367\n",
      "Epoch 46/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5571 - categorical_accuracy: 0.6383\n",
      "Epoch 47/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5324 - categorical_accuracy: 0.6449\n",
      "Epoch 48/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5213 - categorical_accuracy: 0.6439\n",
      "Epoch 49/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5232 - categorical_accuracy: 0.6445\n",
      "Epoch 50/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4902 - categorical_accuracy: 0.6499\n",
      "Epoch 51/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5601 - categorical_accuracy: 0.6391\n",
      "Epoch 52/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4786 - categorical_accuracy: 0.6530\n",
      "Epoch 53/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4779 - categorical_accuracy: 0.6530\n",
      "Epoch 54/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4549 - categorical_accuracy: 0.6570\n",
      "Epoch 55/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.8303 - categorical_accuracy: 0.6045\n",
      "Epoch 56/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4981 - categorical_accuracy: 0.6505\n",
      "Epoch 57/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4671 - categorical_accuracy: 0.6571\n",
      "Epoch 58/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4481 - categorical_accuracy: 0.6608\n",
      "Epoch 59/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4640 - categorical_accuracy: 0.6560\n",
      "Epoch 60/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4378 - categorical_accuracy: 0.6628\n",
      "Epoch 61/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5005 - categorical_accuracy: 0.6565\n",
      "Epoch 62/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.5872 - categorical_accuracy: 0.6386\n",
      "Epoch 63/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4218 - categorical_accuracy: 0.6663\n",
      "Epoch 64/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4174 - categorical_accuracy: 0.6645\n",
      "Epoch 65/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4075 - categorical_accuracy: 0.6694\n",
      "Epoch 66/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4446 - categorical_accuracy: 0.6603\n",
      "Epoch 67/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.7360 - categorical_accuracy: 0.6217\n",
      "Epoch 68/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3723 - categorical_accuracy: 0.6752\n",
      "Epoch 69/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3487 - categorical_accuracy: 0.6837\n",
      "Epoch 70/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3857 - categorical_accuracy: 0.6711\n",
      "Epoch 71/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3887 - categorical_accuracy: 0.6749\n",
      "Epoch 72/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3445 - categorical_accuracy: 0.6808\n",
      "Epoch 73/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.8367 - categorical_accuracy: 0.6129\n",
      "Epoch 74/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4150 - categorical_accuracy: 0.6725\n",
      "Epoch 75/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3737 - categorical_accuracy: 0.6806\n",
      "Epoch 76/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3657 - categorical_accuracy: 0.6815\n",
      "Epoch 77/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3358 - categorical_accuracy: 0.6891\n",
      "Epoch 78/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3606 - categorical_accuracy: 0.6786\n",
      "Epoch 79/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4019 - categorical_accuracy: 0.6734\n",
      "Epoch 80/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3089 - categorical_accuracy: 0.6937\n",
      "Epoch 81/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3114 - categorical_accuracy: 0.6889\n",
      "Epoch 82/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3137 - categorical_accuracy: 0.6883\n",
      "Epoch 83/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3832 - categorical_accuracy: 0.6791\n",
      "Epoch 84/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2778 - categorical_accuracy: 0.6997\n",
      "Epoch 85/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2628 - categorical_accuracy: 0.7018\n",
      "Epoch 86/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.2629 - categorical_accuracy: 0.7018\n",
      "Epoch 87/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2539 - categorical_accuracy: 0.7013\n",
      "Epoch 88/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.2190 - categorical_accuracy: 0.7119\n",
      "Epoch 89/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2473 - categorical_accuracy: 0.7035\n",
      "Epoch 90/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6431 - categorical_accuracy: 0.6527\n",
      "Epoch 91/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2376 - categorical_accuracy: 0.7081\n",
      "Epoch 92/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.2332 - categorical_accuracy: 0.7085\n",
      "Epoch 93/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1972 - categorical_accuracy: 0.7185\n",
      "Epoch 94/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2734 - categorical_accuracy: 0.6987\n",
      "Epoch 95/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3714 - categorical_accuracy: 0.6811\n",
      "Epoch 96/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1849 - categorical_accuracy: 0.7183\n",
      "Epoch 97/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.2603 - categorical_accuracy: 0.7038\n",
      "Epoch 98/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2422 - categorical_accuracy: 0.7066\n",
      "Epoch 99/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4221 - categorical_accuracy: 0.6832\n",
      "Epoch 100/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1744 - categorical_accuracy: 0.7227\n",
      "Epoch 101/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1707 - categorical_accuracy: 0.7211\n",
      "Epoch 102/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2209 - categorical_accuracy: 0.7098\n",
      "Epoch 103/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1787 - categorical_accuracy: 0.7199\n",
      "Epoch 104/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1629 - categorical_accuracy: 0.7201\n",
      "Epoch 105/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2122 - categorical_accuracy: 0.7149\n",
      "Epoch 106/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.5193 - categorical_accuracy: 0.6760\n",
      "Epoch 107/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1561 - categorical_accuracy: 0.7255\n",
      "Epoch 108/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1261 - categorical_accuracy: 0.7316\n",
      "Epoch 109/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1515 - categorical_accuracy: 0.7237\n",
      "Epoch 110/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4911 - categorical_accuracy: 0.6757\n",
      "Epoch 111/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.2676 - categorical_accuracy: 0.7013\n",
      "Epoch 112/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1531 - categorical_accuracy: 0.7295\n",
      "Epoch 113/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1399 - categorical_accuracy: 0.7282\n",
      "Epoch 114/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1253 - categorical_accuracy: 0.7327\n",
      "Epoch 115/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1301 - categorical_accuracy: 0.7285\n",
      "Epoch 116/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1513 - categorical_accuracy: 0.7227\n",
      "Epoch 117/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1322 - categorical_accuracy: 0.7290\n",
      "Epoch 118/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.1257 - categorical_accuracy: 0.7297\n",
      "Epoch 119/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1456 - categorical_accuracy: 0.7257\n",
      "Epoch 120/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4029 - categorical_accuracy: 0.6916\n",
      "Epoch 121/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1653 - categorical_accuracy: 0.7290\n",
      "Epoch 122/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.6428 - categorical_accuracy: 0.6559\n",
      "Epoch 123/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1155 - categorical_accuracy: 0.7367\n",
      "Epoch 124/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1122 - categorical_accuracy: 0.7358\n",
      "Epoch 125/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0920 - categorical_accuracy: 0.7400\n",
      "Epoch 126/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0850 - categorical_accuracy: 0.7403\n",
      "Epoch 127/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0888 - categorical_accuracy: 0.7389\n",
      "Epoch 128/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1330 - categorical_accuracy: 0.7299\n",
      "Epoch 129/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.4299 - categorical_accuracy: 0.6817\n",
      "Epoch 130/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0849 - categorical_accuracy: 0.7435\n",
      "Epoch 131/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0678 - categorical_accuracy: 0.7457\n",
      "Epoch 132/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0814 - categorical_accuracy: 0.7409\n",
      "Epoch 133/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0775 - categorical_accuracy: 0.7418\n",
      "Epoch 134/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2195 - categorical_accuracy: 0.7163\n",
      "Epoch 135/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.1024 - categorical_accuracy: 0.7349\n",
      "Epoch 136/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0852 - categorical_accuracy: 0.7382\n",
      "Epoch 137/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0584 - categorical_accuracy: 0.7446\n",
      "Epoch 138/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4669 - categorical_accuracy: 0.6897\n",
      "Epoch 139/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1783 - categorical_accuracy: 0.7223\n",
      "Epoch 140/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1502 - categorical_accuracy: 0.7334\n",
      "Epoch 141/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0583 - categorical_accuracy: 0.7485\n",
      "Epoch 142/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0788 - categorical_accuracy: 0.7404\n",
      "Epoch 143/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0514 - categorical_accuracy: 0.7464\n",
      "Epoch 144/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.4691 - categorical_accuracy: 0.6861\n",
      "Epoch 145/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0478 - categorical_accuracy: 0.7514\n",
      "Epoch 146/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2670 - categorical_accuracy: 0.7183\n",
      "Epoch 147/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0483 - categorical_accuracy: 0.7517\n",
      "Epoch 148/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0359 - categorical_accuracy: 0.7534\n",
      "Epoch 149/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3472 - categorical_accuracy: 0.7001\n",
      "Epoch 150/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1003 - categorical_accuracy: 0.7409\n",
      "Epoch 151/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1888 - categorical_accuracy: 0.7253\n",
      "Epoch 152/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0394 - categorical_accuracy: 0.7528\n",
      "Epoch 153/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.0916 - categorical_accuracy: 0.7418\n",
      "Epoch 154/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.1734 - categorical_accuracy: 0.7246\n",
      "Epoch 155/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0255 - categorical_accuracy: 0.7571\n",
      "Epoch 156/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0551 - categorical_accuracy: 0.7484\n",
      "Epoch 157/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0268 - categorical_accuracy: 0.7543\n",
      "Epoch 158/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1305 - categorical_accuracy: 0.7318\n",
      "Epoch 159/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0704 - categorical_accuracy: 0.7438\n",
      "Epoch 160/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0251 - categorical_accuracy: 0.7546\n",
      "Epoch 161/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4443 - categorical_accuracy: 0.6867\n",
      "Epoch 162/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0354 - categorical_accuracy: 0.7507\n",
      "Epoch 163/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0113 - categorical_accuracy: 0.7570\n",
      "Epoch 164/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0375 - categorical_accuracy: 0.7508\n",
      "Epoch 165/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0278 - categorical_accuracy: 0.7527\n",
      "Epoch 166/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1121 - categorical_accuracy: 0.7339\n",
      "Epoch 167/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0120 - categorical_accuracy: 0.7601\n",
      "Epoch 168/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.3686 - categorical_accuracy: 0.7030\n",
      "Epoch 169/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0190 - categorical_accuracy: 0.7598\n",
      "Epoch 170/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0287 - categorical_accuracy: 0.7518\n",
      "Epoch 171/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0397 - categorical_accuracy: 0.7501\n",
      "Epoch 172/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2560 - categorical_accuracy: 0.7204\n",
      "Epoch 173/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0912 - categorical_accuracy: 0.7391\n",
      "Epoch 174/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0050 - categorical_accuracy: 0.7596\n",
      "Epoch 175/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 0.9919 - categorical_accuracy: 0.7614\n",
      "Epoch 176/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2087 - categorical_accuracy: 0.7185\n",
      "Epoch 177/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0473 - categorical_accuracy: 0.7500\n",
      "Epoch 178/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9725 - categorical_accuracy: 0.7663\n",
      "Epoch 179/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 0.9896 - categorical_accuracy: 0.7619\n",
      "Epoch 180/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3570 - categorical_accuracy: 0.6984\n",
      "Epoch 181/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0067 - categorical_accuracy: 0.7581\n",
      "Epoch 182/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9662 - categorical_accuracy: 0.7700\n",
      "Epoch 183/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9624 - categorical_accuracy: 0.7692\n",
      "Epoch 184/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9736 - categorical_accuracy: 0.7655\n",
      "Epoch 185/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0773 - categorical_accuracy: 0.7426\n",
      "Epoch 186/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0162 - categorical_accuracy: 0.7540\n",
      "Epoch 187/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0141 - categorical_accuracy: 0.7550\n",
      "Epoch 188/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0855 - categorical_accuracy: 0.7498\n",
      "Epoch 189/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9526 - categorical_accuracy: 0.7726\n",
      "Epoch 190/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9625 - categorical_accuracy: 0.7677\n",
      "Epoch 191/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9536 - categorical_accuracy: 0.7687\n",
      "Epoch 192/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1774 - categorical_accuracy: 0.7269\n",
      "Epoch 193/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0026 - categorical_accuracy: 0.7608\n",
      "Epoch 194/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0907 - categorical_accuracy: 0.7446\n",
      "Epoch 195/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9665 - categorical_accuracy: 0.7662\n",
      "Epoch 196/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9322 - categorical_accuracy: 0.7749\n",
      "Epoch 197/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9748 - categorical_accuracy: 0.7627\n",
      "Epoch 198/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9616 - categorical_accuracy: 0.7647\n",
      "Epoch 199/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2020 - categorical_accuracy: 0.7331\n",
      "Epoch 200/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9732 - categorical_accuracy: 0.7649\n",
      "Epoch 201/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.9257 - categorical_accuracy: 0.7756\n",
      "Epoch 202/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1400 - categorical_accuracy: 0.7432\n",
      "Epoch 203/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9211 - categorical_accuracy: 0.7792\n",
      "Epoch 204/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9334 - categorical_accuracy: 0.7747\n",
      "Epoch 205/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1971 - categorical_accuracy: 0.7289\n",
      "Epoch 206/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9200 - categorical_accuracy: 0.7790\n",
      "Epoch 207/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1165 - categorical_accuracy: 0.7422\n",
      "Epoch 208/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9226 - categorical_accuracy: 0.7788\n",
      "Epoch 209/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0818 - categorical_accuracy: 0.7509\n",
      "Epoch 210/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0134 - categorical_accuracy: 0.7578\n",
      "Epoch 211/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9173 - categorical_accuracy: 0.7765\n",
      "Epoch 212/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.1903 - categorical_accuracy: 0.7326\n",
      "Epoch 213/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9720 - categorical_accuracy: 0.7693\n",
      "Epoch 214/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8913 - categorical_accuracy: 0.7853\n",
      "Epoch 215/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9373 - categorical_accuracy: 0.7705\n",
      "Epoch 216/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9331 - categorical_accuracy: 0.7728\n",
      "Epoch 217/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.0222 - categorical_accuracy: 0.7554\n",
      "Epoch 218/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8958 - categorical_accuracy: 0.7805\n",
      "Epoch 219/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0401 - categorical_accuracy: 0.7528\n",
      "Epoch 220/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8932 - categorical_accuracy: 0.7820\n",
      "Epoch 221/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1467 - categorical_accuracy: 0.7388\n",
      "Epoch 222/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9005 - categorical_accuracy: 0.7826\n",
      "Epoch 223/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8789 - categorical_accuracy: 0.7861\n",
      "Epoch 224/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9809 - categorical_accuracy: 0.7616\n",
      "Epoch 225/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8872 - categorical_accuracy: 0.7818\n",
      "Epoch 226/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9351 - categorical_accuracy: 0.7708\n",
      "Epoch 227/360\n",
      "41400/41400 [==============================] - 4s 98us/sample - loss: 1.0386 - categorical_accuracy: 0.7549\n",
      "Epoch 228/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9121 - categorical_accuracy: 0.7778\n",
      "Epoch 229/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2774 - categorical_accuracy: 0.7248\n",
      "Epoch 230/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8793 - categorical_accuracy: 0.7876\n",
      "Epoch 231/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8865 - categorical_accuracy: 0.7823\n",
      "Epoch 232/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8717 - categorical_accuracy: 0.7859\n",
      "Epoch 233/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.1690 - categorical_accuracy: 0.7375\n",
      "Epoch 234/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8766 - categorical_accuracy: 0.7854\n",
      "Epoch 235/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8899 - categorical_accuracy: 0.7812\n",
      "Epoch 236/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3319 - categorical_accuracy: 0.7095\n",
      "Epoch 237/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8990 - categorical_accuracy: 0.7827\n",
      "Epoch 238/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8907 - categorical_accuracy: 0.7817\n",
      "Epoch 239/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1103 - categorical_accuracy: 0.7453\n",
      "Epoch 240/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8498 - categorical_accuracy: 0.7936\n",
      "Epoch 241/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8920 - categorical_accuracy: 0.7795\n",
      "Epoch 242/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8966 - categorical_accuracy: 0.7801\n",
      "Epoch 243/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8716 - categorical_accuracy: 0.7866\n",
      "Epoch 244/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8862 - categorical_accuracy: 0.7839\n",
      "Epoch 245/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8807 - categorical_accuracy: 0.7845\n",
      "Epoch 246/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9444 - categorical_accuracy: 0.7714\n",
      "Epoch 247/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1926 - categorical_accuracy: 0.7376\n",
      "Epoch 248/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9197 - categorical_accuracy: 0.7755\n",
      "Epoch 249/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8614 - categorical_accuracy: 0.7870\n",
      "Epoch 250/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8722 - categorical_accuracy: 0.7854\n",
      "Epoch 251/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8648 - categorical_accuracy: 0.7871\n",
      "Epoch 252/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.4142 - categorical_accuracy: 0.6985\n",
      "Epoch 253/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9389 - categorical_accuracy: 0.7743\n",
      "Epoch 254/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2355 - categorical_accuracy: 0.7195\n",
      "Epoch 255/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9518 - categorical_accuracy: 0.7703\n",
      "Epoch 256/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9354 - categorical_accuracy: 0.7702\n",
      "Epoch 257/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9308 - categorical_accuracy: 0.7702\n",
      "Epoch 258/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9151 - categorical_accuracy: 0.7764\n",
      "Epoch 259/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0822 - categorical_accuracy: 0.7453\n",
      "Epoch 260/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8544 - categorical_accuracy: 0.7885\n",
      "Epoch 261/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8343 - categorical_accuracy: 0.7933\n",
      "Epoch 262/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1237 - categorical_accuracy: 0.7419\n",
      "Epoch 263/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8948 - categorical_accuracy: 0.7813\n",
      "Epoch 264/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0263 - categorical_accuracy: 0.7594\n",
      "Epoch 265/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.9871 - categorical_accuracy: 0.7592\n",
      "Epoch 266/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9357 - categorical_accuracy: 0.7704\n",
      "Epoch 267/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8735 - categorical_accuracy: 0.7867\n",
      "Epoch 268/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9010 - categorical_accuracy: 0.7787\n",
      "Epoch 269/360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9695 - categorical_accuracy: 0.7656\n",
      "Epoch 270/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8718 - categorical_accuracy: 0.7862\n",
      "Epoch 271/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2542 - categorical_accuracy: 0.7238\n",
      "Epoch 272/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8856 - categorical_accuracy: 0.7856\n",
      "Epoch 273/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8347 - categorical_accuracy: 0.7962\n",
      "Epoch 274/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8594 - categorical_accuracy: 0.7885\n",
      "Epoch 275/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8743 - categorical_accuracy: 0.7851\n",
      "Epoch 276/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8653 - categorical_accuracy: 0.7853\n",
      "Epoch 277/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.2102 - categorical_accuracy: 0.7338\n",
      "Epoch 278/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8656 - categorical_accuracy: 0.7881\n",
      "Epoch 279/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8431 - categorical_accuracy: 0.7934\n",
      "Epoch 280/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.0311 - categorical_accuracy: 0.7536\n",
      "Epoch 281/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8521 - categorical_accuracy: 0.7934\n",
      "Epoch 282/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8480 - categorical_accuracy: 0.7896\n",
      "Epoch 283/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8544 - categorical_accuracy: 0.7899\n",
      "Epoch 284/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1353 - categorical_accuracy: 0.7413\n",
      "Epoch 285/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8364 - categorical_accuracy: 0.7942\n",
      "Epoch 286/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8684 - categorical_accuracy: 0.7841\n",
      "Epoch 287/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.1025 - categorical_accuracy: 0.7537\n",
      "Epoch 288/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8193 - categorical_accuracy: 0.8007\n",
      "Epoch 289/360\n",
      "41400/41400 [==============================] - 4s 101us/sample - loss: 0.8110 - categorical_accuracy: 0.7999\n",
      "Epoch 290/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8549 - categorical_accuracy: 0.7892\n",
      "Epoch 291/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8902 - categorical_accuracy: 0.7840\n",
      "Epoch 292/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.0189 - categorical_accuracy: 0.7630\n",
      "Epoch 293/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8112 - categorical_accuracy: 0.8032\n",
      "Epoch 294/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8440 - categorical_accuracy: 0.7917\n",
      "Epoch 295/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.3794 - categorical_accuracy: 0.7200\n",
      "Epoch 296/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8290 - categorical_accuracy: 0.7981\n",
      "Epoch 297/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8196 - categorical_accuracy: 0.7995\n",
      "Epoch 298/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8364 - categorical_accuracy: 0.7921\n",
      "Epoch 299/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.9290 - categorical_accuracy: 0.7793\n",
      "Epoch 300/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9969 - categorical_accuracy: 0.7664\n",
      "Epoch 301/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8026 - categorical_accuracy: 0.8027\n",
      "Epoch 302/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7953 - categorical_accuracy: 0.8031\n",
      "Epoch 303/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0210 - categorical_accuracy: 0.7660\n",
      "Epoch 304/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9296 - categorical_accuracy: 0.7770\n",
      "Epoch 305/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.9039 - categorical_accuracy: 0.7808\n",
      "Epoch 306/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8024 - categorical_accuracy: 0.8015\n",
      "Epoch 307/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7920 - categorical_accuracy: 0.8036\n",
      "Epoch 308/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7837 - categorical_accuracy: 0.8045\n",
      "Epoch 309/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.0150 - categorical_accuracy: 0.7605\n",
      "Epoch 310/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2708 - categorical_accuracy: 0.7218\n",
      "Epoch 311/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8535 - categorical_accuracy: 0.7913\n",
      "Epoch 312/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8002 - categorical_accuracy: 0.8048\n",
      "Epoch 313/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9966 - categorical_accuracy: 0.7710\n",
      "Epoch 314/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8827 - categorical_accuracy: 0.7869\n",
      "Epoch 315/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8725 - categorical_accuracy: 0.7857\n",
      "Epoch 316/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7801 - categorical_accuracy: 0.8074\n",
      "Epoch 317/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8138 - categorical_accuracy: 0.7964\n",
      "Epoch 318/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8350 - categorical_accuracy: 0.7925\n",
      "Epoch 319/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8170 - categorical_accuracy: 0.7968\n",
      "Epoch 320/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8432 - categorical_accuracy: 0.7932\n",
      "Epoch 321/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.9399 - categorical_accuracy: 0.7762\n",
      "Epoch 322/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0622 - categorical_accuracy: 0.7519\n",
      "Epoch 323/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7925 - categorical_accuracy: 0.8045\n",
      "Epoch 324/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7920 - categorical_accuracy: 0.8032\n",
      "Epoch 325/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.4149 - categorical_accuracy: 0.7208\n",
      "Epoch 326/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8471 - categorical_accuracy: 0.7938\n",
      "Epoch 327/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7807 - categorical_accuracy: 0.8087\n",
      "Epoch 328/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7917 - categorical_accuracy: 0.8032\n",
      "Epoch 329/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9385 - categorical_accuracy: 0.7729\n",
      "Epoch 330/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7738 - categorical_accuracy: 0.8096\n",
      "Epoch 331/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7817 - categorical_accuracy: 0.8047\n",
      "Epoch 332/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 1.2628 - categorical_accuracy: 0.7257\n",
      "Epoch 333/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9742 - categorical_accuracy: 0.7729\n",
      "Epoch 334/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7877 - categorical_accuracy: 0.8067\n",
      "Epoch 335/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7775 - categorical_accuracy: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7726 - categorical_accuracy: 0.8079\n",
      "Epoch 337/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.1135 - categorical_accuracy: 0.7491\n",
      "Epoch 338/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8107 - categorical_accuracy: 0.7994\n",
      "Epoch 339/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7851 - categorical_accuracy: 0.8057\n",
      "Epoch 340/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0365 - categorical_accuracy: 0.7602\n",
      "Epoch 341/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7689 - categorical_accuracy: 0.8093\n",
      "Epoch 342/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7766 - categorical_accuracy: 0.8066\n",
      "Epoch 343/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.2606 - categorical_accuracy: 0.7331\n",
      "Epoch 344/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7715 - categorical_accuracy: 0.8108\n",
      "Epoch 345/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8203 - categorical_accuracy: 0.7948\n",
      "Epoch 346/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.8938 - categorical_accuracy: 0.7777\n",
      "Epoch 347/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7972 - categorical_accuracy: 0.8022\n",
      "Epoch 348/360\n",
      "41400/41400 [==============================] - 4s 101us/sample - loss: 0.7771 - categorical_accuracy: 0.8060\n",
      "Epoch 349/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7601 - categorical_accuracy: 0.8111\n",
      "Epoch 350/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0938 - categorical_accuracy: 0.7461\n",
      "Epoch 351/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7661 - categorical_accuracy: 0.8093\n",
      "Epoch 352/360\n",
      "41400/41400 [==============================] - 4s 100us/sample - loss: 0.7576 - categorical_accuracy: 0.8110\n",
      "Epoch 353/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.9783 - categorical_accuracy: 0.7644\n",
      "Epoch 354/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7571 - categorical_accuracy: 0.8121\n",
      "Epoch 355/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8754 - categorical_accuracy: 0.7850\n",
      "Epoch 356/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7705 - categorical_accuracy: 0.8069\n",
      "Epoch 357/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8062 - categorical_accuracy: 0.8009\n",
      "Epoch 358/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 1.0913 - categorical_accuracy: 0.7484\n",
      "Epoch 359/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.8042 - categorical_accuracy: 0.7981\n",
      "Epoch 360/360\n",
      "41400/41400 [==============================] - 4s 99us/sample - loss: 0.7696 - categorical_accuracy: 0.8077\n",
      "\n",
      "history dict: {'loss': [4.5150237622468365, 3.8315303118332573, 3.21604467474896, 2.649509278587673, 2.333727030132128, 2.1693426090738046, 2.0702601474264393, 1.9985620892566183, 1.96274646261464, 1.92894170595252, 1.9168588855992192, 1.9998890835305918, 1.842939627688864, 1.848963565411775, 1.785626424913821, 1.8289018496223117, 2.5442180011583413, 1.8604036082392152, 1.7875087468520454, 1.7776100272717683, 1.7279572818590248, 1.7140905929648358, 2.20171334432519, 1.7650974957839303, 1.7318913138431051, 1.719822593357252, 1.6977966795796933, 1.6674410726713098, 1.6429585975149403, 1.6343388028766799, 1.7958175959794418, 1.6328228950500487, 1.6090504013973734, 1.6384144731189894, 1.6031917748243913, 1.5863791704177856, 1.606717085838318, 1.5485923134762307, 1.7965428766996965, 1.5595800959545634, 1.547912219296331, 1.533662161619767, 1.5254710902338442, 1.886663835981618, 1.5717658136201942, 1.5570842929508375, 1.532392464513364, 1.5212518857873005, 1.5231903148734052, 1.490186735858088, 1.5600778341293335, 1.478639499000881, 1.4779367395069287, 1.4549415868261586, 1.8303077376407126, 1.498122819610264, 1.4670792755873308, 1.4481019061544667, 1.463994230394778, 1.437773409097091, 1.5005055240962817, 1.5871746954710588, 1.4218083993248318, 1.4174374404160872, 1.407476926886517, 1.4446338622466377, 1.7360360456549604, 1.3723125644352125, 1.3487183011096457, 1.385699226545251, 1.3886514259421308, 1.3444656890371571, 1.836710937126823, 1.4150145230085953, 1.3736927561137988, 1.365673265249833, 1.3358218462570854, 1.360565361769303, 1.4018799501916637, 1.308920443576315, 1.311388091419054, 1.3136722720187644, 1.3831794002781743, 1.2777597852375195, 1.2628254807513692, 1.262908467002537, 1.2538601414017054, 1.218955305348272, 1.247256216795548, 1.6430625739304916, 1.237629583089248, 1.2331895112991333, 1.1971684461054595, 1.2734078054842741, 1.3714280097380929, 1.184896447347558, 1.2602609504824098, 1.242180839828823, 1.4220726940942847, 1.1743678538695626, 1.1706737331722095, 1.220862389129141, 1.1786943560061247, 1.1628950761712116, 1.2121554410975912, 1.519338073419488, 1.156095918365147, 1.1260561196700387, 1.1515015109725621, 1.4911361901656441, 1.2675862654395726, 1.1530862284743268, 1.1398747065792914, 1.125325401969578, 1.130081349870433, 1.1513028222581614, 1.1322227913400402, 1.1257038893906965, 1.1455865144729613, 1.4028761547544728, 1.1652547924414924, 1.642803626993428, 1.1155420474384141, 1.1121756874996682, 1.0919868759486986, 1.0849959440853285, 1.0887748210326484, 1.132984723733819, 1.429900362180627, 1.0848647174627886, 1.067766619246939, 1.0813538504683453, 1.07750774414643, 1.2195006894028706, 1.1024478907170503, 1.085193855866142, 1.058416659935661, 1.4669319520825925, 1.1782921754795572, 1.150230384391287, 1.058298518865005, 1.0787831835124804, 1.0514124310534934, 1.469133430460225, 1.0478157318156698, 1.266995608288309, 1.0482561593470365, 1.0359395991200986, 1.347187238154204, 1.100318295541017, 1.1887682287589363, 1.0394005848013836, 1.0915919148403666, 1.1733706101127293, 1.0255341680153556, 1.055071638978046, 1.0268131079881087, 1.1305370361908622, 1.0703937561615653, 1.0251092034837475, 1.4443282656047656, 1.0354299348333607, 1.0113269386084183, 1.0374531466027965, 1.0278120367423347, 1.1121271465135658, 1.0119798473689867, 1.3685774445533752, 1.0189865236696989, 1.0287142753601075, 1.0396569480066713, 1.2559905321701714, 1.0911913586699444, 1.0050227279248445, 0.9918824465378471, 1.2087411978970404, 1.047299745808477, 0.9724588114282359, 0.9896289073902628, 1.3569799646087315, 1.0066593683284262, 0.9662023907122405, 0.9623635794805444, 0.9736215036848317, 1.0772891998291017, 1.0162409502526988, 1.0141254855238873, 1.0855192132618117, 0.9525664386541947, 0.9625345639560534, 0.9535525835078695, 1.1773532701575238, 1.0026414622431217, 1.090660453879315, 0.9664998287739961, 0.9321760390115821, 0.974769203559212, 0.9615546195403389, 1.202049614035565, 0.973180762062902, 0.9256775747174802, 1.1399898928144703, 0.9210510098415873, 0.9333986157956331, 1.1970550625220588, 0.9200022412383038, 1.1164580376251885, 0.9226350618445355, 1.081829772306525, 1.013428569358328, 0.9172633824141129, 1.1902984380722046, 0.9719727241474649, 0.8913045624028082, 0.9372917589933976, 0.9331340292225714, 1.0221797704696656, 0.8958350487377332, 1.040106295502704, 0.8931757040645765, 1.1467327242312224, 0.9004579010217086, 0.878887156818224, 0.9809429878773896, 0.8872102058452108, 0.9350716139959252, 1.0385749236397122, 0.9121118244917497, 1.277431469378264, 0.8792577645053035, 0.8864550310632456, 0.8716759391452955, 1.1690345582754715, 0.8765817585198775, 0.889872291813726, 1.3319318424100461, 0.898951562591221, 0.8907193930252738, 1.1103297803712928, 0.8498166307159092, 0.8920240132705025, 0.8966340018355328, 0.8715543150901794, 0.8861887874810592, 0.8806908286136129, 0.9444211011347563, 1.1926038353339485, 0.919655728340149, 0.8614340077275815, 0.8722496804983719, 0.8648291535999464, 1.414161921584088, 0.9388937970866328, 1.2354678278384001, 0.9518482213434966, 0.9354288997857467, 0.9307997739833335, 0.9150994378587474, 1.0822017498638319, 0.8544222790261974, 0.8342973688374395, 1.1236535424771517, 0.8947587541911913, 1.0263038308724113, 0.9871083834896917, 0.9356551025224769, 0.8735328389250714, 0.9010143295578334, 0.9695078839426455, 0.8717656130376069, 1.2542466645655426, 0.8856004720148833, 0.8347398275914399, 0.8593782725541488, 0.8743056494256725, 0.8653097417043603, 1.2102134808250096, 0.8656260402306266, 0.8431417309719583, 1.0310543355734452, 0.8521188735961914, 0.848022435022437, 0.8543780979902847, 1.13525064147037, 0.8363574002100074, 0.8683533601138903, 1.1025072724922844, 0.8192825027134107, 0.8110304324523262, 0.8549066870108895, 0.8901699377142864, 1.0189045631367228, 0.8111844814342001, 0.8439611305361209, 1.3794209573579872, 0.8289516547451848, 0.8195966627286828, 0.8364457322203595, 0.9289661702902421, 0.9969408175219661, 0.8026036744532378, 0.7952613400376362, 1.0209968167802561, 0.9296460441921068, 0.9038644179053928, 0.8024352265440899, 0.7919920174971871, 0.783733418195144, 1.01503818138786, 1.2707707918208577, 0.853464562996574, 0.8001513025035029, 0.9966050386428833, 0.8826613467672597, 0.8724729688271232, 0.7800717825474947, 0.8137967493223107, 0.8349743262581203, 0.817015348310056, 0.843229501662047, 0.9398943045864935, 1.0622391047685042, 0.7924839133801668, 0.7920195050861525, 1.4149347336395928, 0.847054286106773, 0.7806857570357945, 0.7917012142098468, 0.9384653200273928, 0.7737988347592561, 0.7817260939141978, 1.2627816262452498, 0.9741750893385513, 0.7876776337623597, 0.7775180878846542, 0.7725509513979373, 1.1135202112405196, 0.810682093060535, 0.7850968868836112, 1.0364864463391512, 0.7688529854235442, 0.7766322426173998, 1.260577915025794, 0.771484330944393, 0.8203310645144919, 0.8938405166501584, 0.7971934168235115, 0.7771310132482777, 0.7601257412329964, 1.0938361287117004, 0.7661170130190642, 0.7576296085896699, 0.9783494726471279, 0.7571249049642812, 0.8754398672477058, 0.7705349403878917, 0.8062120779700901, 1.0912895088610441, 0.8042159661002781, 0.769601135150246], 'categorical_accuracy': [0.10398551, 0.23437198, 0.37381643, 0.47103864, 0.5163044, 0.54251206, 0.5615942, 0.57258457, 0.5745169, 0.58483094, 0.5810145, 0.5691304, 0.59693235, 0.5948792, 0.6049517, 0.5967633, 0.5265942, 0.60347825, 0.60954106, 0.6080918, 0.6164976, 0.61608696, 0.5552657, 0.61502415, 0.6157971, 0.61722225, 0.62091786, 0.62280196, 0.627029, 0.62608695, 0.60002416, 0.6309903, 0.63253623, 0.6275121, 0.6311111, 0.63577294, 0.62939614, 0.6376812, 0.6066667, 0.6405314, 0.63958937, 0.6433092, 0.6427536, 0.5900966, 0.63673913, 0.6383333, 0.6448551, 0.6439372, 0.6444686, 0.64992756, 0.63908213, 0.65304345, 0.65304345, 0.657029, 0.6045169, 0.6504831, 0.6571256, 0.66082126, 0.6560145, 0.6627778, 0.65652174, 0.6386473, 0.666256, 0.6644927, 0.66937196, 0.660314, 0.6216908, 0.6751691, 0.68374395, 0.6710628, 0.6749034, 0.68084544, 0.61294687, 0.67251205, 0.6805797, 0.6814976, 0.6891063, 0.6786232, 0.6734058, 0.69369566, 0.6888647, 0.68833333, 0.67913043, 0.6997343, 0.70183575, 0.70183575, 0.70125604, 0.7118599, 0.70352656, 0.6527053, 0.7080918, 0.7084783, 0.71852654, 0.6986715, 0.6810628, 0.718285, 0.7037923, 0.70661837, 0.6832367, 0.722657, 0.72113526, 0.7097826, 0.7198792, 0.72007245, 0.7148551, 0.6759662, 0.7254831, 0.73157007, 0.7236715, 0.6757246, 0.70125604, 0.7294686, 0.72821254, 0.7327295, 0.7284541, 0.7227053, 0.72896135, 0.7297343, 0.72572464, 0.6916425, 0.7290097, 0.65586954, 0.73671496, 0.7358454, 0.74, 0.74033815, 0.73891306, 0.72992754, 0.6816667, 0.7434541, 0.7457246, 0.7408937, 0.74178743, 0.716256, 0.73492754, 0.7382367, 0.7445652, 0.68971014, 0.7222947, 0.7333816, 0.74847823, 0.74036235, 0.7464493, 0.68608695, 0.7513768, 0.71830916, 0.751715, 0.75335747, 0.70014495, 0.74091786, 0.725314, 0.7528261, 0.7418116, 0.72461355, 0.75705314, 0.7483816, 0.7542995, 0.7318116, 0.7437923, 0.75456524, 0.68671495, 0.7507246, 0.7569565, 0.7507971, 0.7527295, 0.73391306, 0.7600966, 0.7030193, 0.75980675, 0.7517874, 0.7501449, 0.7203623, 0.73913044, 0.7595894, 0.76142514, 0.71852654, 0.74997586, 0.7663285, 0.76188403, 0.69835746, 0.7580676, 0.7700242, 0.7692029, 0.7654831, 0.7425845, 0.7539855, 0.755, 0.7498309, 0.7726087, 0.767657, 0.7686715, 0.72688407, 0.7608213, 0.74463767, 0.7662319, 0.77492756, 0.7627053, 0.7647101, 0.733116, 0.76490337, 0.77562803, 0.7432126, 0.7792271, 0.774686, 0.72888887, 0.7789855, 0.7421739, 0.7787681, 0.75094205, 0.75777775, 0.7764976, 0.7326329, 0.7692995, 0.7852657, 0.7705073, 0.77280194, 0.7554348, 0.78050727, 0.75280195, 0.7819565, 0.7388406, 0.7826087, 0.7861111, 0.7616184, 0.7818116, 0.7708454, 0.75487924, 0.7778261, 0.7248068, 0.7876087, 0.7822947, 0.785942, 0.7374638, 0.7853865, 0.7811594, 0.7095411, 0.78272945, 0.781715, 0.74528986, 0.79364735, 0.7794686, 0.7801208, 0.7865701, 0.783913, 0.78451693, 0.77144927, 0.7375604, 0.77545893, 0.7869807, 0.78541064, 0.78705317, 0.6984783, 0.77427536, 0.7194686, 0.77028984, 0.77024156, 0.7701691, 0.7763768, 0.74533814, 0.78847826, 0.79333335, 0.74188405, 0.781256, 0.7594444, 0.7591546, 0.7704348, 0.7866667, 0.7787198, 0.7655797, 0.7861836, 0.72381645, 0.785628, 0.7961836, 0.78847826, 0.78507245, 0.78533816, 0.7337681, 0.78806764, 0.79343, 0.7536232, 0.79338163, 0.78961354, 0.78985506, 0.74125606, 0.79422706, 0.784058, 0.75374395, 0.8007005, 0.79985505, 0.78922707, 0.78403383, 0.7629952, 0.80316424, 0.7916667, 0.7200483, 0.7981401, 0.7994686, 0.7921498, 0.7793237, 0.7664493, 0.80268115, 0.8030676, 0.7659662, 0.7769565, 0.78082126, 0.8014976, 0.80364734, 0.8044686, 0.76045895, 0.72178745, 0.79130435, 0.8047584, 0.7709662, 0.7868599, 0.7856763, 0.8074396, 0.7964493, 0.79251206, 0.79678744, 0.79321253, 0.77620775, 0.75188404, 0.8044686, 0.8031884, 0.7207729, 0.7937681, 0.8087198, 0.8032367, 0.7729227, 0.80956525, 0.80471015, 0.72565216, 0.7729227, 0.8066667, 0.80809176, 0.80785024, 0.74905795, 0.79939616, 0.8057005, 0.76024157, 0.8092754, 0.80664253, 0.73306763, 0.81082124, 0.7948309, 0.77772945, 0.8021739, 0.80599034, 0.8111111, 0.7460628, 0.8092754, 0.81099033, 0.7644445, 0.8121256, 0.78502417, 0.8069324, 0.8008696, 0.7484058, 0.79809177, 0.8077295]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the training configuration (optimizer, loss, metrics)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "# Train the model by slicing the data into \"batches\"\n",
    "# of size \"batch_size\", and repeatedly iterating over\n",
    "# the entire dataset for a given number of \"epochs\"\n",
    "print('# Fit model on training data')\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=360,\n",
    "                    epochs=360)\n",
    "\n",
    "# The returned \"history\" object holds a record\n",
    "# of the loss values and metric values during training\n",
    "print('\\nhistory dict:', history.history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(\"./data/test_idall_et10_row60_col3273_Delunique.csv\")\n",
    "x_test.rename(columns = {'Unnamed: 0' : 'index'}, inplace = True)\n",
    "index = x_test[\"index\"]\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x.head()\n",
    "# df_x.iloc[:,1:-1].head().shape\n",
    "x_test = x_test.iloc[:,1:]\n",
    "x_hat = MinMaxScaler().fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>V0000</th>\n",
       "      <th>V0001</th>\n",
       "      <th>V0002</th>\n",
       "      <th>V0003</th>\n",
       "      <th>V0004</th>\n",
       "      <th>V0005</th>\n",
       "      <th>V0006</th>\n",
       "      <th>V0007</th>\n",
       "      <th>V0008</th>\n",
       "      <th>...</th>\n",
       "      <th>V5087</th>\n",
       "      <th>V5088</th>\n",
       "      <th>V5089</th>\n",
       "      <th>V5090</th>\n",
       "      <th>V5115</th>\n",
       "      <th>V5116</th>\n",
       "      <th>V5117</th>\n",
       "      <th>V5118</th>\n",
       "      <th>V5119</th>\n",
       "      <th>V5120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>30.465741</td>\n",
       "      <td>8.618514</td>\n",
       "      <td>8.705075</td>\n",
       "      <td>8.730912</td>\n",
       "      <td>8.699214</td>\n",
       "      <td>181.327530</td>\n",
       "      <td>201.889419</td>\n",
       "      <td>2.393806e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229694</td>\n",
       "      <td>-0.172642</td>\n",
       "      <td>-0.181698</td>\n",
       "      <td>43.203640</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>30.477302</td>\n",
       "      <td>8.642689</td>\n",
       "      <td>8.713423</td>\n",
       "      <td>8.732450</td>\n",
       "      <td>8.694666</td>\n",
       "      <td>203.347675</td>\n",
       "      <td>155.790045</td>\n",
       "      <td>-1.808861e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232155</td>\n",
       "      <td>-0.177659</td>\n",
       "      <td>-0.164828</td>\n",
       "      <td>43.195677</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>30.478336</td>\n",
       "      <td>8.675928</td>\n",
       "      <td>8.729837</td>\n",
       "      <td>8.672877</td>\n",
       "      <td>8.710215</td>\n",
       "      <td>196.673652</td>\n",
       "      <td>227.039249</td>\n",
       "      <td>6.236627e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249112</td>\n",
       "      <td>-0.193733</td>\n",
       "      <td>-0.170861</td>\n",
       "      <td>43.192395</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>30.462904</td>\n",
       "      <td>8.733765</td>\n",
       "      <td>8.706455</td>\n",
       "      <td>8.691974</td>\n",
       "      <td>8.696285</td>\n",
       "      <td>194.365551</td>\n",
       "      <td>167.436935</td>\n",
       "      <td>2.845012e-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240052</td>\n",
       "      <td>-0.166091</td>\n",
       "      <td>-0.164244</td>\n",
       "      <td>43.195476</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>30.483675</td>\n",
       "      <td>8.807382</td>\n",
       "      <td>8.680733</td>\n",
       "      <td>8.713651</td>\n",
       "      <td>8.664766</td>\n",
       "      <td>205.369347</td>\n",
       "      <td>154.245975</td>\n",
       "      <td>-2.085638e-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230030</td>\n",
       "      <td>-0.228277</td>\n",
       "      <td>-0.139462</td>\n",
       "      <td>43.193896</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>85.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3274 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      V0000     V0001     V0002     V0003     V0004       V0005  \\\n",
       "0   1000  30.465741  8.618514  8.705075  8.730912  8.699214  181.327530   \n",
       "1   1000  30.477302  8.642689  8.713423  8.732450  8.694666  203.347675   \n",
       "2   1000  30.478336  8.675928  8.729837  8.672877  8.710215  196.673652   \n",
       "3   1000  30.462904  8.733765  8.706455  8.691974  8.696285  194.365551   \n",
       "4   1000  30.483675  8.807382  8.680733  8.713651  8.664766  205.369347   \n",
       "\n",
       "        V0006         V0007  V0008  ...     V5087     V5088     V5089  \\\n",
       "0  201.889419  2.393806e-19    0.0  ... -0.229694 -0.172642 -0.181698   \n",
       "1  155.790045 -1.808861e-19    0.0  ... -0.232155 -0.177659 -0.164828   \n",
       "2  227.039249  6.236627e-19    0.0  ... -0.249112 -0.193733 -0.170861   \n",
       "3  167.436935  2.845012e-20    0.0  ... -0.240052 -0.166091 -0.164244   \n",
       "4  154.245975 -2.085638e-19    0.0  ... -0.230030 -0.228277 -0.139462   \n",
       "\n",
       "       V5090  V5115  V5116  V5117     V5118  V5119  V5120  \n",
       "0  43.203640   60.0    0.0    0.0  0.000004   85.4    0.0  \n",
       "1  43.195677   60.0    0.0    0.0  0.000005   85.4    0.0  \n",
       "2  43.192395   60.0    0.0    0.0  0.000016   85.4    0.0  \n",
       "3  43.195476   60.0    0.0    0.0 -0.000010   85.4    0.0  \n",
       "4  43.193896   60.0    0.0    0.0 -0.000008   85.4    0.0  \n",
       "\n",
       "[5 rows x 3274 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.rename(columns = {'Unnamed: 0' : 'index'}, inplace = True)\n",
    "index = x_test[\"index\"]\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=predict)\n",
    "submission.index = index\n",
    "submission.index.name = 'id'\n",
    "submission = submission.sort_index()\n",
    "submission = submission.groupby('id').mean()\n",
    "submission.to_csv('./data/submission_DL_10_60초_1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>7.543903e-29</td>\n",
       "      <td>1.248639e-28</td>\n",
       "      <td>1.184104e-34</td>\n",
       "      <td>1.490804e-30</td>\n",
       "      <td>6.654520e-10</td>\n",
       "      <td>7.510398e-03</td>\n",
       "      <td>1.272096e-21</td>\n",
       "      <td>1.568129e-29</td>\n",
       "      <td>2.982815e-32</td>\n",
       "      <td>3.654265e-26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.005685e-40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.983025e-21</td>\n",
       "      <td>1.230944e-23</td>\n",
       "      <td>3.131805e-29</td>\n",
       "      <td>3.246725e-31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.913925e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.863040e-03</td>\n",
       "      <td>1.285591e-08</td>\n",
       "      <td>2.912834e-29</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.885213e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.968917e-02</td>\n",
       "      <td>1.846766e-04</td>\n",
       "      <td>6.260771e-28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.318764e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.710640e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.869751e-01</td>\n",
       "      <td>7.740746e-06</td>\n",
       "      <td>2.539408e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.733493e-32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>7.433870e-36</td>\n",
       "      <td>1.853035e-32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.412814e-34</td>\n",
       "      <td>3.729045e-08</td>\n",
       "      <td>1.929949e-02</td>\n",
       "      <td>1.520837e-23</td>\n",
       "      <td>8.071005e-33</td>\n",
       "      <td>3.237378e-32</td>\n",
       "      <td>5.377916e-31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.692809e-26</td>\n",
       "      <td>1.765881e-28</td>\n",
       "      <td>7.907528e-34</td>\n",
       "      <td>3.536355e-34</td>\n",
       "      <td>1.231894e-38</td>\n",
       "      <td>7.591742e-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4    \\\n",
       "id                                                                          \n",
       "828  7.543903e-29  1.248639e-28  1.184104e-34  1.490804e-30  6.654520e-10   \n",
       "829  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  2.863040e-03   \n",
       "830  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.968917e-02   \n",
       "831  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  5.869751e-01   \n",
       "832  7.433870e-36  1.853035e-32  0.000000e+00  5.412814e-34  3.729045e-08   \n",
       "\n",
       "              5             6             7             8             9    \\\n",
       "id                                                                          \n",
       "828  7.510398e-03  1.272096e-21  1.568129e-29  2.982815e-32  3.654265e-26   \n",
       "829  1.285591e-08  2.912834e-29  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "830  1.846766e-04  6.260771e-28  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "831  7.740746e-06  2.539408e-24  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "832  1.929949e-02  1.520837e-23  8.071005e-33  3.237378e-32  5.377916e-31   \n",
       "\n",
       "     ...           188           189  190  191           192           193  \\\n",
       "id   ...                                                                     \n",
       "828  ...  0.000000e+00  6.005685e-40  0.0  0.0  1.983025e-21  1.230944e-23   \n",
       "829  ...  0.000000e+00  0.000000e+00  0.0  0.0  2.885213e-34  0.000000e+00   \n",
       "830  ...  2.318764e-38  0.000000e+00  0.0  0.0  1.710640e-34  0.000000e+00   \n",
       "831  ...  0.000000e+00  0.000000e+00  0.0  0.0  1.733493e-32  0.000000e+00   \n",
       "832  ...  0.000000e+00  0.000000e+00  0.0  0.0  2.692809e-26  1.765881e-28   \n",
       "\n",
       "              194           195           196           197  \n",
       "id                                                           \n",
       "828  3.131805e-29  3.246725e-31  0.000000e+00  8.913925e-25  \n",
       "829  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "830  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "831  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "832  7.907528e-34  3.536355e-34  1.231894e-38  7.591742e-30  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-5dacb4a27011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
