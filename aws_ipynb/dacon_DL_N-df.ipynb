{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color 전처리 파일 load\n",
    "train_color = pd.read_csv('./data/dacon_g/train_colorindex.csv', index_col='id')\n",
    "test_color = pd.read_csv('./data/dacon_g/test_colorindex.csv', index_col='id')\n",
    "sample_submission = pd.read_csv('./data/dacon_g/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0          8\n",
       "1          8\n",
       "2          8\n",
       "3          8\n",
       "4         10\n",
       "          ..\n",
       "199986     8\n",
       "199987     6\n",
       "199988    10\n",
       "199989     6\n",
       "199990     8\n",
       "Name: type_num, Length: 199991, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_color_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color 전처리\n",
    "column_number = {}\n",
    "for i, column in enumerate(sample_submission.columns):\n",
    "    column_number[column] = i\n",
    "    \n",
    "def to_number(x, dic):\n",
    "    return dic[x]\n",
    "\n",
    "train_color['type_num'] = train_color['type'].apply(lambda x: to_number(x, column_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_color_x = train_color.drop(columns=['Unnamed: 0','type', 'fiberID','type_num'], axis=1)\n",
    "train_color_y = train_color['type_num']\n",
    "test_color_x = test_color.drop(columns=['fiberID','Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교체할 것\n",
    "# train_x = train.drop(columns=['type', 'fiberID','type_num'], axis=1)\n",
    "# train_y = train['type_num']\n",
    "# test_x = test.drop(columns=['fiberID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psfMag_g</th>\n",
       "      <th>fiberMag_g</th>\n",
       "      <th>petroMag_g</th>\n",
       "      <th>modelMag_g</th>\n",
       "      <th>fiber_u-g</th>\n",
       "      <th>fiber_g-r</th>\n",
       "      <th>fiber_r-i</th>\n",
       "      <th>fiber_i-z</th>\n",
       "      <th>psf_u-g</th>\n",
       "      <th>psf_g-r</th>\n",
       "      <th>psf_r-i</th>\n",
       "      <th>psf_i-z</th>\n",
       "      <th>petro_u-g</th>\n",
       "      <th>petro_g-r</th>\n",
       "      <th>petro_r-i</th>\n",
       "      <th>petro_i-z</th>\n",
       "      <th>model_u-g</th>\n",
       "      <th>model_g-r</th>\n",
       "      <th>model_r-i</th>\n",
       "      <th>model_i-z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>22.508963</td>\n",
       "      <td>23.167848</td>\n",
       "      <td>22.796239</td>\n",
       "      <td>22.499435</td>\n",
       "      <td>1.886041</td>\n",
       "      <td>1.831947</td>\n",
       "      <td>2.500043</td>\n",
       "      <td>1.401474</td>\n",
       "      <td>1.308437</td>\n",
       "      <td>1.527857</td>\n",
       "      <td>2.463790</td>\n",
       "      <td>1.441237</td>\n",
       "      <td>-0.549543</td>\n",
       "      <td>1.600924</td>\n",
       "      <td>2.610829</td>\n",
       "      <td>1.430202</td>\n",
       "      <td>2.892099</td>\n",
       "      <td>1.487517</td>\n",
       "      <td>2.512577</td>\n",
       "      <td>1.407867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>21.937111</td>\n",
       "      <td>22.186000</td>\n",
       "      <td>21.837511</td>\n",
       "      <td>21.853442</td>\n",
       "      <td>0.312564</td>\n",
       "      <td>1.567121</td>\n",
       "      <td>0.317676</td>\n",
       "      <td>0.271126</td>\n",
       "      <td>0.869872</td>\n",
       "      <td>1.601341</td>\n",
       "      <td>0.335258</td>\n",
       "      <td>0.473143</td>\n",
       "      <td>-0.107680</td>\n",
       "      <td>1.641382</td>\n",
       "      <td>0.228925</td>\n",
       "      <td>0.283532</td>\n",
       "      <td>0.621896</td>\n",
       "      <td>1.680273</td>\n",
       "      <td>0.376412</td>\n",
       "      <td>0.229385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>19.235669</td>\n",
       "      <td>19.439533</td>\n",
       "      <td>18.710223</td>\n",
       "      <td>18.653338</td>\n",
       "      <td>1.766013</td>\n",
       "      <td>1.095100</td>\n",
       "      <td>0.434743</td>\n",
       "      <td>0.371526</td>\n",
       "      <td>1.788581</td>\n",
       "      <td>0.931608</td>\n",
       "      <td>0.495453</td>\n",
       "      <td>0.428495</td>\n",
       "      <td>2.012406</td>\n",
       "      <td>1.098371</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>0.314533</td>\n",
       "      <td>1.925976</td>\n",
       "      <td>1.091230</td>\n",
       "      <td>0.441579</td>\n",
       "      <td>0.411782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>20.286261</td>\n",
       "      <td>20.611498</td>\n",
       "      <td>20.385262</td>\n",
       "      <td>20.280943</td>\n",
       "      <td>0.364634</td>\n",
       "      <td>0.044237</td>\n",
       "      <td>0.087944</td>\n",
       "      <td>0.201846</td>\n",
       "      <td>0.217164</td>\n",
       "      <td>0.089057</td>\n",
       "      <td>0.034785</td>\n",
       "      <td>0.102587</td>\n",
       "      <td>-0.055993</td>\n",
       "      <td>0.256105</td>\n",
       "      <td>-0.077418</td>\n",
       "      <td>-0.005768</td>\n",
       "      <td>0.198937</td>\n",
       "      <td>0.130443</td>\n",
       "      <td>-0.055721</td>\n",
       "      <td>0.113311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>22.668237</td>\n",
       "      <td>22.935289</td>\n",
       "      <td>22.957496</td>\n",
       "      <td>22.857290</td>\n",
       "      <td>2.746572</td>\n",
       "      <td>1.292832</td>\n",
       "      <td>2.017531</td>\n",
       "      <td>1.033176</td>\n",
       "      <td>1.576614</td>\n",
       "      <td>1.428904</td>\n",
       "      <td>1.954555</td>\n",
       "      <td>1.048838</td>\n",
       "      <td>-0.649198</td>\n",
       "      <td>1.672463</td>\n",
       "      <td>1.985913</td>\n",
       "      <td>0.991593</td>\n",
       "      <td>2.632069</td>\n",
       "      <td>1.665429</td>\n",
       "      <td>1.953898</td>\n",
       "      <td>0.957596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209995</th>\n",
       "      <td>19.542406</td>\n",
       "      <td>19.827172</td>\n",
       "      <td>19.549257</td>\n",
       "      <td>19.536518</td>\n",
       "      <td>0.266136</td>\n",
       "      <td>0.113140</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>-0.122836</td>\n",
       "      <td>0.222629</td>\n",
       "      <td>0.103120</td>\n",
       "      <td>0.081328</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.333472</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.154203</td>\n",
       "      <td>-0.180028</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>0.104056</td>\n",
       "      <td>0.056017</td>\n",
       "      <td>0.021469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209996</th>\n",
       "      <td>19.609379</td>\n",
       "      <td>19.928523</td>\n",
       "      <td>19.635609</td>\n",
       "      <td>19.604800</td>\n",
       "      <td>0.391391</td>\n",
       "      <td>0.232261</td>\n",
       "      <td>-0.067509</td>\n",
       "      <td>0.356659</td>\n",
       "      <td>0.350651</td>\n",
       "      <td>0.283430</td>\n",
       "      <td>-0.065341</td>\n",
       "      <td>0.132427</td>\n",
       "      <td>0.449845</td>\n",
       "      <td>0.253686</td>\n",
       "      <td>-0.078593</td>\n",
       "      <td>0.069652</td>\n",
       "      <td>0.461752</td>\n",
       "      <td>0.270688</td>\n",
       "      <td>-0.067127</td>\n",
       "      <td>0.241828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209997</th>\n",
       "      <td>20.276182</td>\n",
       "      <td>20.551190</td>\n",
       "      <td>20.315201</td>\n",
       "      <td>20.255485</td>\n",
       "      <td>0.703264</td>\n",
       "      <td>0.185390</td>\n",
       "      <td>0.164928</td>\n",
       "      <td>0.270447</td>\n",
       "      <td>0.945717</td>\n",
       "      <td>0.185407</td>\n",
       "      <td>0.163567</td>\n",
       "      <td>0.160476</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.078475</td>\n",
       "      <td>0.177925</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>0.790016</td>\n",
       "      <td>0.113936</td>\n",
       "      <td>0.235535</td>\n",
       "      <td>-0.047918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209998</th>\n",
       "      <td>21.624585</td>\n",
       "      <td>21.950139</td>\n",
       "      <td>21.516809</td>\n",
       "      <td>21.589489</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.339334</td>\n",
       "      <td>0.109336</td>\n",
       "      <td>-0.140342</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.531206</td>\n",
       "      <td>-0.098396</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.803365</td>\n",
       "      <td>0.245884</td>\n",
       "      <td>0.074906</td>\n",
       "      <td>-0.135510</td>\n",
       "      <td>0.111280</td>\n",
       "      <td>0.461158</td>\n",
       "      <td>-0.302196</td>\n",
       "      <td>0.209625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209999</th>\n",
       "      <td>16.531405</td>\n",
       "      <td>16.836321</td>\n",
       "      <td>16.575405</td>\n",
       "      <td>16.530546</td>\n",
       "      <td>0.910766</td>\n",
       "      <td>0.334699</td>\n",
       "      <td>0.128307</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.906956</td>\n",
       "      <td>0.345387</td>\n",
       "      <td>0.151131</td>\n",
       "      <td>0.038956</td>\n",
       "      <td>0.905898</td>\n",
       "      <td>0.353467</td>\n",
       "      <td>0.118454</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.354272</td>\n",
       "      <td>0.130452</td>\n",
       "      <td>0.050008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10009 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         psfMag_g  fiberMag_g  petroMag_g  modelMag_g  fiber_u-g  fiber_g-r  \\\n",
       "id                                                                            \n",
       "199991  22.508963   23.167848   22.796239   22.499435   1.886041   1.831947   \n",
       "199992  21.937111   22.186000   21.837511   21.853442   0.312564   1.567121   \n",
       "199993  19.235669   19.439533   18.710223   18.653338   1.766013   1.095100   \n",
       "199994  20.286261   20.611498   20.385262   20.280943   0.364634   0.044237   \n",
       "199995  22.668237   22.935289   22.957496   22.857290   2.746572   1.292832   \n",
       "...           ...         ...         ...         ...        ...        ...   \n",
       "209995  19.542406   19.827172   19.549257   19.536518   0.266136   0.113140   \n",
       "209996  19.609379   19.928523   19.635609   19.604800   0.391391   0.232261   \n",
       "209997  20.276182   20.551190   20.315201   20.255485   0.703264   0.185390   \n",
       "209998  21.624585   21.950139   21.516809   21.589489   0.092803   0.339334   \n",
       "209999  16.531405   16.836321   16.575405   16.530546   0.910766   0.334699   \n",
       "\n",
       "        fiber_r-i  fiber_i-z   psf_u-g   psf_g-r   psf_r-i   psf_i-z  \\\n",
       "id                                                                     \n",
       "199991   2.500043   1.401474  1.308437  1.527857  2.463790  1.441237   \n",
       "199992   0.317676   0.271126  0.869872  1.601341  0.335258  0.473143   \n",
       "199993   0.434743   0.371526  1.788581  0.931608  0.495453  0.428495   \n",
       "199994   0.087944   0.201846  0.217164  0.089057  0.034785  0.102587   \n",
       "199995   2.017531   1.033176  1.576614  1.428904  1.954555  1.048838   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "209995   0.027172  -0.122836  0.222629  0.103120  0.081328  0.000652   \n",
       "209996  -0.067509   0.356659  0.350651  0.283430 -0.065341  0.132427   \n",
       "209997   0.164928   0.270447  0.945717  0.185407  0.163567  0.160476   \n",
       "209998   0.109336  -0.140342  0.000884  0.531206 -0.098396  0.005178   \n",
       "209999   0.128307   0.037476  0.906956  0.345387  0.151131  0.038956   \n",
       "\n",
       "        petro_u-g  petro_g-r  petro_r-i  petro_i-z  model_u-g  model_g-r  \\\n",
       "id                                                                         \n",
       "199991  -0.549543   1.600924   2.610829   1.430202   2.892099   1.487517   \n",
       "199992  -0.107680   1.641382   0.228925   0.283532   0.621896   1.680273   \n",
       "199993   2.012406   1.098371   0.453332   0.314533   1.925976   1.091230   \n",
       "199994  -0.055993   0.256105  -0.077418  -0.005768   0.198937   0.130443   \n",
       "199995  -0.649198   1.672463   1.985913   0.991593   2.632069   1.665429   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "209995   0.333472   0.091692   0.154203  -0.180028   0.255663   0.104056   \n",
       "209996   0.449845   0.253686  -0.078593   0.069652   0.461752   0.270688   \n",
       "209997   0.682819   0.078475   0.177925   0.070438   0.790016   0.113936   \n",
       "209998   0.803365   0.245884   0.074906  -0.135510   0.111280   0.461158   \n",
       "209999   0.905898   0.353467   0.118454   0.051025   0.913772   0.354272   \n",
       "\n",
       "        model_r-i  model_i-z  \n",
       "id                            \n",
       "199991   2.512577   1.407867  \n",
       "199992   0.376412   0.229385  \n",
       "199993   0.441579   0.411782  \n",
       "199994  -0.055721   0.113311  \n",
       "199995   1.953898   0.957596  \n",
       "...           ...        ...  \n",
       "209995   0.056017   0.021469  \n",
       "209996  -0.067127   0.241828  \n",
       "209997   0.235535  -0.047918  \n",
       "209998  -0.302196   0.209625  \n",
       "209999   0.130452   0.050008  \n",
       "\n",
       "[10009 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_color_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mat = scaler.fit_transform(train_color_x)\n",
    "train_x = pd.DataFrame(_mat, columns=train_color_x.columns, index=train_color_x.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_color_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159992 samples, validate on 39999 samples\n",
      "Epoch 1/300\n",
      " - 19s - loss: 2.6074 - accuracy: 0.2865 - val_loss: 1.7047 - val_accuracy: 0.4664\n",
      "Epoch 2/300\n",
      " - 19s - loss: 1.5117 - accuracy: 0.5182 - val_loss: 1.1425 - val_accuracy: 0.5925\n",
      "Epoch 3/300\n",
      " - 19s - loss: 1.1279 - accuracy: 0.6126 - val_loss: 0.8612 - val_accuracy: 0.7117\n",
      "Epoch 4/300\n",
      " - 19s - loss: 0.9132 - accuracy: 0.6964 - val_loss: 0.7029 - val_accuracy: 0.7761\n",
      "Epoch 5/300\n",
      " - 19s - loss: 0.7954 - accuracy: 0.7414 - val_loss: 0.6245 - val_accuracy: 0.7983\n",
      "Epoch 6/300\n",
      " - 19s - loss: 0.7291 - accuracy: 0.7650 - val_loss: 0.5939 - val_accuracy: 0.8106\n",
      "Epoch 7/300\n",
      " - 19s - loss: 0.6753 - accuracy: 0.7819 - val_loss: 0.5578 - val_accuracy: 0.8238\n",
      "Epoch 8/300\n",
      " - 19s - loss: 0.6514 - accuracy: 0.7911 - val_loss: 0.5413 - val_accuracy: 0.8286\n",
      "Epoch 9/300\n",
      " - 19s - loss: 0.6196 - accuracy: 0.8007 - val_loss: 0.5221 - val_accuracy: 0.8313\n",
      "Epoch 10/300\n",
      " - 19s - loss: 0.5983 - accuracy: 0.8068 - val_loss: 0.5161 - val_accuracy: 0.8319\n",
      "Epoch 11/300\n",
      " - 19s - loss: 0.5778 - accuracy: 0.8129 - val_loss: 0.5022 - val_accuracy: 0.8338\n",
      "Epoch 12/300\n",
      " - 19s - loss: 0.5635 - accuracy: 0.8182 - val_loss: 0.4881 - val_accuracy: 0.8400\n",
      "Epoch 13/300\n",
      " - 19s - loss: 0.5454 - accuracy: 0.8224 - val_loss: 0.4914 - val_accuracy: 0.8379\n",
      "Epoch 14/300\n",
      " - 19s - loss: 0.5343 - accuracy: 0.8252 - val_loss: 0.4763 - val_accuracy: 0.8406\n",
      "Epoch 15/300\n",
      " - 19s - loss: 0.5239 - accuracy: 0.8284 - val_loss: 0.4696 - val_accuracy: 0.8443\n",
      "Epoch 16/300\n",
      " - 19s - loss: 0.5128 - accuracy: 0.8304 - val_loss: 0.4599 - val_accuracy: 0.8453\n",
      "Epoch 17/300\n",
      " - 19s - loss: 0.5089 - accuracy: 0.8340 - val_loss: 0.4562 - val_accuracy: 0.8449\n",
      "Epoch 18/300\n",
      " - 19s - loss: 0.4922 - accuracy: 0.8358 - val_loss: 0.4434 - val_accuracy: 0.8496\n",
      "Epoch 19/300\n",
      " - 19s - loss: 0.4839 - accuracy: 0.8381 - val_loss: 0.4399 - val_accuracy: 0.8505\n",
      "Epoch 20/300\n",
      " - 19s - loss: 0.4786 - accuracy: 0.8411 - val_loss: 0.4375 - val_accuracy: 0.8510\n",
      "Epoch 21/300\n",
      " - 19s - loss: 0.4708 - accuracy: 0.8419 - val_loss: 0.4236 - val_accuracy: 0.8554\n",
      "Epoch 22/300\n",
      " - 19s - loss: 0.4653 - accuracy: 0.8442 - val_loss: 0.4218 - val_accuracy: 0.8560\n",
      "Epoch 23/300\n",
      " - 19s - loss: 0.4765 - accuracy: 0.8452 - val_loss: 0.4231 - val_accuracy: 0.8557\n",
      "Epoch 24/300\n",
      " - 19s - loss: 0.4547 - accuracy: 0.8473 - val_loss: 0.4219 - val_accuracy: 0.8545\n",
      "Epoch 25/300\n",
      " - 19s - loss: 0.4504 - accuracy: 0.8482 - val_loss: 0.4151 - val_accuracy: 0.8576\n",
      "Epoch 26/300\n",
      " - 19s - loss: 0.4455 - accuracy: 0.8493 - val_loss: 0.4116 - val_accuracy: 0.8584\n",
      "Epoch 27/300\n",
      " - 19s - loss: 0.4456 - accuracy: 0.8499 - val_loss: 0.4060 - val_accuracy: 0.8595\n",
      "Epoch 28/300\n",
      " - 19s - loss: 0.4415 - accuracy: 0.8503 - val_loss: 0.4074 - val_accuracy: 0.8597\n",
      "Epoch 29/300\n",
      " - 19s - loss: 0.4373 - accuracy: 0.8512 - val_loss: 0.4139 - val_accuracy: 0.8592\n",
      "Epoch 30/300\n",
      " - 19s - loss: 0.4344 - accuracy: 0.8526 - val_loss: 0.4092 - val_accuracy: 0.8601\n",
      "Epoch 31/300\n",
      " - 19s - loss: 0.4322 - accuracy: 0.8533 - val_loss: 0.4016 - val_accuracy: 0.8623\n",
      "Epoch 32/300\n",
      " - 19s - loss: 0.4337 - accuracy: 0.8537 - val_loss: 0.3997 - val_accuracy: 0.8619\n",
      "Epoch 33/300\n",
      " - 19s - loss: 0.4266 - accuracy: 0.8536 - val_loss: 0.4017 - val_accuracy: 0.8617\n",
      "Epoch 34/300\n",
      " - 19s - loss: 0.4250 - accuracy: 0.8551 - val_loss: 0.4029 - val_accuracy: 0.8609\n",
      "Epoch 35/300\n",
      " - 19s - loss: 0.4282 - accuracy: 0.8562 - val_loss: 0.3979 - val_accuracy: 0.8613\n",
      "Epoch 36/300\n",
      " - 19s - loss: 0.4207 - accuracy: 0.8567 - val_loss: 0.3935 - val_accuracy: 0.8629\n",
      "Epoch 37/300\n",
      " - 19s - loss: 0.4190 - accuracy: 0.8561 - val_loss: 0.3985 - val_accuracy: 0.8638\n",
      "Epoch 38/300\n",
      " - 19s - loss: 0.4192 - accuracy: 0.8570 - val_loss: 0.4038 - val_accuracy: 0.8624\n",
      "Epoch 39/300\n",
      " - 19s - loss: 0.4174 - accuracy: 0.8566 - val_loss: 0.3985 - val_accuracy: 0.8625\n",
      "Epoch 40/300\n",
      " - 19s - loss: 0.4142 - accuracy: 0.8579 - val_loss: 0.3928 - val_accuracy: 0.8642\n",
      "Epoch 41/300\n",
      " - 19s - loss: 0.4126 - accuracy: 0.8587 - val_loss: 0.3866 - val_accuracy: 0.8650\n",
      "Epoch 42/300\n",
      " - 19s - loss: 0.4123 - accuracy: 0.8586 - val_loss: 0.3851 - val_accuracy: 0.8670\n",
      "Epoch 43/300\n",
      " - 19s - loss: 0.4097 - accuracy: 0.8586 - val_loss: 0.3998 - val_accuracy: 0.8650\n",
      "Epoch 44/300\n",
      " - 19s - loss: 0.4213 - accuracy: 0.8598 - val_loss: 0.3852 - val_accuracy: 0.8669\n",
      "Epoch 45/300\n",
      " - 19s - loss: 0.4067 - accuracy: 0.8600 - val_loss: 0.3839 - val_accuracy: 0.8671\n",
      "Epoch 46/300\n",
      " - 19s - loss: 0.4053 - accuracy: 0.8601 - val_loss: 0.3802 - val_accuracy: 0.8686\n",
      "Epoch 47/300\n",
      " - 19s - loss: 0.4049 - accuracy: 0.8597 - val_loss: 0.3837 - val_accuracy: 0.8668\n",
      "Epoch 48/300\n",
      " - 19s - loss: 0.4026 - accuracy: 0.8615 - val_loss: 0.3841 - val_accuracy: 0.8665\n",
      "Epoch 49/300\n",
      " - 19s - loss: 0.4018 - accuracy: 0.8626 - val_loss: 0.3773 - val_accuracy: 0.8687\n",
      "Epoch 50/300\n",
      " - 19s - loss: 0.4007 - accuracy: 0.8615 - val_loss: 0.3803 - val_accuracy: 0.8671\n",
      "Epoch 51/300\n",
      " - 19s - loss: 0.3994 - accuracy: 0.8625 - val_loss: 0.3793 - val_accuracy: 0.8676\n",
      "Epoch 52/300\n",
      " - 19s - loss: 0.3985 - accuracy: 0.8630 - val_loss: 0.3846 - val_accuracy: 0.8668\n",
      "Epoch 53/300\n",
      " - 19s - loss: 0.3984 - accuracy: 0.8627 - val_loss: 0.3826 - val_accuracy: 0.8655\n",
      "Epoch 54/300\n",
      " - 19s - loss: 0.3965 - accuracy: 0.8632 - val_loss: 0.3744 - val_accuracy: 0.8704\n",
      "Epoch 55/300\n",
      " - 19s - loss: 0.3945 - accuracy: 0.8628 - val_loss: 0.3766 - val_accuracy: 0.8682\n",
      "Epoch 56/300\n",
      " - 19s - loss: 0.3963 - accuracy: 0.8628 - val_loss: 0.3768 - val_accuracy: 0.8693\n",
      "Epoch 57/300\n",
      " - 19s - loss: 0.3947 - accuracy: 0.8633 - val_loss: 0.3765 - val_accuracy: 0.8681\n",
      "Epoch 58/300\n",
      " - 19s - loss: 0.3938 - accuracy: 0.8639 - val_loss: 0.3760 - val_accuracy: 0.8700\n",
      "Epoch 59/300\n",
      " - 19s - loss: 0.3912 - accuracy: 0.8644 - val_loss: 0.3761 - val_accuracy: 0.8678\n",
      "Epoch 60/300\n",
      " - 21s - loss: 0.3901 - accuracy: 0.8651 - val_loss: 0.3737 - val_accuracy: 0.8696\n",
      "Epoch 61/300\n",
      " - 19s - loss: 0.3881 - accuracy: 0.8652 - val_loss: 0.3733 - val_accuracy: 0.8698\n",
      "Epoch 62/300\n",
      " - 19s - loss: 0.4178 - accuracy: 0.8651 - val_loss: 0.3693 - val_accuracy: 0.8715\n",
      "Epoch 63/300\n",
      " - 19s - loss: 0.3875 - accuracy: 0.8662 - val_loss: 0.3725 - val_accuracy: 0.8692\n",
      "Epoch 64/300\n",
      " - 19s - loss: 0.3847 - accuracy: 0.8663 - val_loss: 0.3730 - val_accuracy: 0.8699\n",
      "Epoch 65/300\n",
      " - 19s - loss: 0.3852 - accuracy: 0.8666 - val_loss: 0.3698 - val_accuracy: 0.8708\n",
      "Epoch 66/300\n",
      " - 19s - loss: 0.3828 - accuracy: 0.8662 - val_loss: 0.3744 - val_accuracy: 0.8695\n",
      "Epoch 67/300\n",
      " - 19s - loss: 0.3825 - accuracy: 0.8664 - val_loss: 0.3694 - val_accuracy: 0.8712\n",
      "Epoch 68/300\n",
      " - 19s - loss: 0.3814 - accuracy: 0.8676 - val_loss: 0.3669 - val_accuracy: 0.8723\n",
      "Epoch 69/300\n",
      " - 19s - loss: 0.3815 - accuracy: 0.8676 - val_loss: 0.3703 - val_accuracy: 0.8705\n",
      "Epoch 70/300\n",
      " - 19s - loss: 0.3808 - accuracy: 0.8671 - val_loss: 0.3729 - val_accuracy: 0.8708\n",
      "Epoch 71/300\n",
      " - 19s - loss: 0.3802 - accuracy: 0.8677 - val_loss: 0.3695 - val_accuracy: 0.8703\n",
      "Epoch 72/300\n",
      " - 19s - loss: 0.3821 - accuracy: 0.8673 - val_loss: 0.3671 - val_accuracy: 0.8724\n",
      "Epoch 73/300\n",
      " - 19s - loss: 0.3788 - accuracy: 0.8681 - val_loss: 0.3663 - val_accuracy: 0.8718\n",
      "Epoch 74/300\n",
      " - 19s - loss: 0.3784 - accuracy: 0.8685 - val_loss: 0.3639 - val_accuracy: 0.8735\n",
      "Epoch 75/300\n",
      " - 19s - loss: 0.3774 - accuracy: 0.8687 - val_loss: 0.3688 - val_accuracy: 0.8707\n",
      "Epoch 76/300\n",
      " - 19s - loss: 0.3757 - accuracy: 0.8690 - val_loss: 0.3717 - val_accuracy: 0.8697\n",
      "Epoch 77/300\n",
      " - 19s - loss: 0.3770 - accuracy: 0.8680 - val_loss: 0.3654 - val_accuracy: 0.8734\n",
      "Epoch 78/300\n",
      " - 19s - loss: 0.3772 - accuracy: 0.8678 - val_loss: 0.3661 - val_accuracy: 0.8735\n",
      "Epoch 79/300\n",
      " - 19s - loss: 0.3762 - accuracy: 0.8679 - val_loss: 0.3690 - val_accuracy: 0.8724\n",
      "Epoch 80/300\n",
      " - 19s - loss: 0.3762 - accuracy: 0.8683 - val_loss: 0.3692 - val_accuracy: 0.8718\n",
      "Epoch 81/300\n",
      " - 19s - loss: 0.3759 - accuracy: 0.8687 - val_loss: 0.3729 - val_accuracy: 0.8698\n",
      "Epoch 82/300\n",
      " - 19s - loss: 0.3749 - accuracy: 0.8684 - val_loss: 0.3651 - val_accuracy: 0.8735\n",
      "Epoch 83/300\n",
      " - 19s - loss: 0.3750 - accuracy: 0.8693 - val_loss: 0.3685 - val_accuracy: 0.8711\n",
      "Epoch 84/300\n",
      " - 19s - loss: 0.3768 - accuracy: 0.8689 - val_loss: 0.3670 - val_accuracy: 0.8723\n",
      "Epoch 85/300\n",
      " - 19s - loss: 0.3697 - accuracy: 0.8706 - val_loss: 0.3637 - val_accuracy: 0.8731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/300\n",
      " - 19s - loss: 0.3700 - accuracy: 0.8698 - val_loss: 0.3677 - val_accuracy: 0.8720\n",
      "Epoch 87/300\n",
      " - 19s - loss: 0.3708 - accuracy: 0.8705 - val_loss: 0.3656 - val_accuracy: 0.8739\n",
      "Epoch 88/300\n",
      " - 19s - loss: 0.3705 - accuracy: 0.8699 - val_loss: 0.3662 - val_accuracy: 0.8711\n",
      "Epoch 89/300\n",
      " - 19s - loss: 0.3790 - accuracy: 0.8694 - val_loss: 0.3673 - val_accuracy: 0.8732\n",
      "Epoch 90/300\n",
      " - 19s - loss: 0.3687 - accuracy: 0.8702 - val_loss: 0.3675 - val_accuracy: 0.8704\n",
      "Epoch 91/300\n",
      " - 26s - loss: 0.3691 - accuracy: 0.8706 - val_loss: 0.3649 - val_accuracy: 0.8736\n",
      "Epoch 92/300\n",
      " - 24s - loss: 0.3679 - accuracy: 0.8714 - val_loss: 0.3613 - val_accuracy: 0.8735\n",
      "Epoch 93/300\n",
      " - 29s - loss: 0.3673 - accuracy: 0.8714 - val_loss: 0.3653 - val_accuracy: 0.8719\n",
      "Epoch 94/300\n",
      " - 19s - loss: 0.3682 - accuracy: 0.8707 - val_loss: 0.3631 - val_accuracy: 0.8738\n",
      "Epoch 95/300\n",
      " - 19s - loss: 0.3673 - accuracy: 0.8711 - val_loss: 0.3636 - val_accuracy: 0.8731\n",
      "Epoch 96/300\n",
      " - 19s - loss: 0.3653 - accuracy: 0.8715 - val_loss: 0.3647 - val_accuracy: 0.8745\n",
      "Epoch 97/300\n",
      " - 19s - loss: 0.3669 - accuracy: 0.8714 - val_loss: 0.3677 - val_accuracy: 0.8719\n",
      "Epoch 98/300\n",
      " - 22s - loss: 0.3649 - accuracy: 0.8718 - val_loss: 0.3698 - val_accuracy: 0.8716\n",
      "Epoch 99/300\n",
      " - 23s - loss: 0.3667 - accuracy: 0.8713 - val_loss: 0.3649 - val_accuracy: 0.8734\n",
      "Epoch 100/300\n",
      " - 24s - loss: 0.3683 - accuracy: 0.8719 - val_loss: 0.3623 - val_accuracy: 0.8748\n",
      "Epoch 101/300\n",
      " - 23s - loss: 0.3660 - accuracy: 0.8717 - val_loss: 0.3638 - val_accuracy: 0.8747\n",
      "Epoch 102/300\n",
      " - 19s - loss: 0.3620 - accuracy: 0.8726 - val_loss: 0.3654 - val_accuracy: 0.8738\n",
      "Epoch 103/300\n",
      " - 19s - loss: 0.3627 - accuracy: 0.8715 - val_loss: 0.3637 - val_accuracy: 0.8734\n",
      "Epoch 104/300\n",
      " - 19s - loss: 0.3627 - accuracy: 0.8723 - val_loss: 0.3651 - val_accuracy: 0.8730\n",
      "Epoch 105/300\n",
      " - 19s - loss: 0.3622 - accuracy: 0.8721 - val_loss: 0.3624 - val_accuracy: 0.8736\n",
      "Epoch 106/300\n",
      " - 19s - loss: 0.3625 - accuracy: 0.8726 - val_loss: 0.3623 - val_accuracy: 0.8746\n",
      "Epoch 107/300\n",
      " - 19s - loss: 0.3618 - accuracy: 0.8718 - val_loss: 0.3621 - val_accuracy: 0.8740\n",
      "Epoch 108/300\n",
      " - 19s - loss: 0.3607 - accuracy: 0.8725 - val_loss: 0.3639 - val_accuracy: 0.8742\n",
      "Epoch 109/300\n",
      " - 19s - loss: 0.3608 - accuracy: 0.8733 - val_loss: 0.3632 - val_accuracy: 0.8750\n",
      "Epoch 110/300\n",
      " - 19s - loss: 0.3604 - accuracy: 0.8727 - val_loss: 0.3655 - val_accuracy: 0.8732\n",
      "Epoch 111/300\n",
      " - 19s - loss: 0.3589 - accuracy: 0.8738 - val_loss: 0.3615 - val_accuracy: 0.8745\n",
      "Epoch 112/300\n",
      " - 19s - loss: 0.3645 - accuracy: 0.8728 - val_loss: 0.3608 - val_accuracy: 0.8744\n",
      "Epoch 113/300\n",
      " - 19s - loss: 0.3592 - accuracy: 0.8729 - val_loss: 0.3627 - val_accuracy: 0.8734\n",
      "Epoch 114/300\n",
      " - 19s - loss: 0.3579 - accuracy: 0.8741 - val_loss: 0.3635 - val_accuracy: 0.8744\n",
      "Epoch 115/300\n",
      " - 19s - loss: 0.3579 - accuracy: 0.8743 - val_loss: 0.3628 - val_accuracy: 0.8746\n",
      "Epoch 116/300\n",
      " - 19s - loss: 0.3574 - accuracy: 0.8735 - val_loss: 0.3643 - val_accuracy: 0.8744\n",
      "Epoch 117/300\n",
      " - 19s - loss: 0.3604 - accuracy: 0.8741 - val_loss: 0.3673 - val_accuracy: 0.8723\n",
      "Epoch 118/300\n",
      " - 19s - loss: 0.3570 - accuracy: 0.8736 - val_loss: 0.3639 - val_accuracy: 0.8735\n",
      "Epoch 119/300\n",
      " - 19s - loss: 0.3562 - accuracy: 0.8742 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
      "Epoch 120/300\n",
      " - 19s - loss: 0.3557 - accuracy: 0.8742 - val_loss: 0.3651 - val_accuracy: 0.8727\n",
      "Epoch 121/300\n",
      " - 19s - loss: 0.3563 - accuracy: 0.8738 - val_loss: 0.3662 - val_accuracy: 0.8736\n",
      "Epoch 122/300\n",
      " - 19s - loss: 0.3548 - accuracy: 0.8747 - val_loss: 0.3652 - val_accuracy: 0.8730\n",
      "Epoch 123/300\n",
      " - 19s - loss: 0.3549 - accuracy: 0.8748 - val_loss: 0.3630 - val_accuracy: 0.8752\n",
      "Epoch 124/300\n",
      " - 19s - loss: 0.3729 - accuracy: 0.8740 - val_loss: 0.3633 - val_accuracy: 0.8738\n",
      "Epoch 125/300\n",
      " - 19s - loss: 0.3548 - accuracy: 0.8748 - val_loss: 0.3644 - val_accuracy: 0.8729\n",
      "Epoch 126/300\n",
      " - 19s - loss: 0.3541 - accuracy: 0.8747 - val_loss: 0.3636 - val_accuracy: 0.8743\n",
      "Epoch 127/300\n",
      " - 19s - loss: 0.3529 - accuracy: 0.8747 - val_loss: 0.3647 - val_accuracy: 0.8746\n",
      "Epoch 128/300\n",
      " - 19s - loss: 0.3555 - accuracy: 0.8747 - val_loss: 0.3631 - val_accuracy: 0.8747\n",
      "Epoch 129/300\n",
      " - 19s - loss: 0.3511 - accuracy: 0.8755 - val_loss: 0.3624 - val_accuracy: 0.8745\n",
      "Epoch 130/300\n",
      " - 19s - loss: 0.3513 - accuracy: 0.8755 - val_loss: 0.3627 - val_accuracy: 0.8745\n",
      "Epoch 131/300\n",
      " - 19s - loss: 0.3505 - accuracy: 0.8760 - val_loss: 0.3646 - val_accuracy: 0.8751\n",
      "Epoch 132/300\n",
      " - 19s - loss: 0.3506 - accuracy: 0.8761 - val_loss: 0.3636 - val_accuracy: 0.8720\n",
      "Epoch 133/300\n",
      " - 19s - loss: 0.3500 - accuracy: 0.8763 - val_loss: 0.3628 - val_accuracy: 0.8742\n",
      "Epoch 134/300\n",
      " - 19s - loss: 0.3506 - accuracy: 0.8753 - val_loss: 0.3645 - val_accuracy: 0.8755\n",
      "Epoch 135/300\n",
      " - 19s - loss: 0.3495 - accuracy: 0.8758 - val_loss: 0.3636 - val_accuracy: 0.8752\n",
      "Epoch 136/300\n",
      " - 19s - loss: 0.3501 - accuracy: 0.8756 - val_loss: 0.3641 - val_accuracy: 0.8735\n",
      "Epoch 137/300\n",
      " - 19s - loss: 0.3496 - accuracy: 0.8761 - val_loss: 0.3622 - val_accuracy: 0.8739\n",
      "Epoch 138/300\n",
      " - 19s - loss: 0.3504 - accuracy: 0.8754 - val_loss: 0.3653 - val_accuracy: 0.8745\n",
      "Epoch 139/300\n",
      " - 19s - loss: 0.3493 - accuracy: 0.8763 - val_loss: 0.3630 - val_accuracy: 0.8755\n",
      "Epoch 00139: early stopping\n",
      "CPU times: user 2h 27min 30s, sys: 1min 53s, total: 2h 29min 23s\n",
      "Wall time: 44min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(Dense(256, kernel_initializer='random_uniform', input_shape=(20,), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform',  activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, kernel_initializer='random_uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(19, kernel_initializer='random_uniform', activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "# Adadelta(learning_rate=1.0, rho=0.95)\n",
    "Adamax = optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "Adam = optimizers.Adam(learning_rate=0.0005,amsgrad=True)\n",
    "model.compile(optimizer=Adamax, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    " \n",
    "# 4. 모델 학습시키기\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "hist = model.fit(train_x, train_y, epochs=300, batch_size = 256*2, callbacks=[early_stopping,mc], validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test1 = pd.DataFrame(scaler.transform(test_color_x), columns=test_color_x.columns, index=test_color_x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mat = model.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.4866156e-14, 5.2194810e-07, 3.4550685e-05, ..., 2.6785806e-08,\n",
       "        2.3176090e-05, 3.2420689e-06],\n",
       "       [4.1028168e-05, 3.3701617e-06, 1.0900740e-09, ..., 1.2810546e-09,\n",
       "        1.9092156e-05, 5.4314086e-04],\n",
       "       [3.9668307e-06, 5.1303942e-07, 3.9750504e-20, ..., 3.7887085e-06,\n",
       "        1.6173497e-06, 5.2409177e-08],\n",
       "       ...,\n",
       "       [1.1279975e-04, 1.5110738e-04, 1.1076196e-12, ..., 1.5231346e-13,\n",
       "        2.2826967e-05, 6.7254834e-02],\n",
       "       [1.4781172e-09, 9.2716568e-13, 8.0528927e-14, ..., 3.1450019e-23,\n",
       "        7.6489757e-09, 5.7735661e-04],\n",
       "       [5.8410849e-05, 3.1726231e-06, 2.5909770e-20, ..., 4.1048955e-14,\n",
       "        2.9478587e-08, 4.4994213e-06]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=pred_mat, columns=sample_submission.columns, index=sample_submission.index)\n",
    "submission.to_csv('./data/dacon_g/submission_DL_2_1.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
