### *** 자기소개 ***

\1. 졸업(예정) 시기를 기재해주세요.
\2. 지원하는 분야와 관련하여 학습한 전공과목 혹은 외부강의를 3개 이내로 기재해주세요.
\3. 자신의 열정과 기술적인 전문성을 나타낼 수 있는 경험/이력/생각을 자유롭게 기술해주세요.(대회, 해커톤, 프로젝트, 오픈소스 코드 기여, 논문 등

```reStructuredText
졸업시기 : 2018-02

1. 전문 교육
데이터 과학자를 위한 1000시간 여정

파이썬, R을 활용한 탐색적 데이터분석기술 부터 머신러닝/딥러닝에 필요한 고급기술 교육을 학습하였습니다.


2. 외부 활동

공모전
산업 AI 해커톤 ‘Factory HACK’에 참가한 적이 있습니다. 산업데이터에 관심이 많은 후배와 참가하여 실제 제조환경에서 나온 데이터를 가지고 문제 해결을 위한 알고리즘을 22시간 안에 개발하는 해커톤이었습니다. 

설비 센서 데이터를 활용해 생산품의 양/불량품을 예측하고 예측정확도를 시간에 따라 보전하는 알고리즘을 개발하는 것이었습니다. 하지만 실제 설비 데이터라 불량품이 0.6%밖에 없어 기존 방법으로는 모델을 학습시키기에 부적절하였습니다. 게다가 보안으로 인해 데이터 익명화가 되어 있어 산업공학도로서 도메인 지식을 활용할 수 없었습니다.
 그러다 EDA를 진행하던 중 데이터가 생산주기로 일정하게 패턴을 보이는 것을 발견하였습니다. 그래서 대회 참가 전 학습한 CNN 알고리즘을 적용해 보기로 하였습니다. 원래 이미지, 주파수 데이터 학습에 최적화된 알고리즘이지만 센서데이터를 합치면 패턴을 시각화하여 문제를 해결할 수도 있다는 생각이 문뜩 들었습니다. 다른 팀 대부분 업샘플링을 통한 데이터 모델을 구축하였는데 체리픽킹이라는 생각이 들어 실제 제조환경에 맞지 않는다고 생각했기 때문입니다. 
그리하여 생산 cycle time에 맞춰 모든 데이터의 시각화를 통해 새로운 방법론으로 접근할 수 있다는 결과를 발표하게 되었습니다. 비록 수상은 못 하였지만 참신한 방법론으로 아이디어 칭찬을 받은 도전적인 경험이었습니다


컴페티션

‘DACON’의 원자력발전소 상태판단 대회에 출전한 적이 있습니다. 원자력 상태를 측정하는 5,120개의 센서 데이터를 학습해 상태 변화를 예측하는 알고리즘을 구축하는 대회였습니다. 팀원들 모두 처음 경험하는 대회여서 중간 등수만 해도 성공이라는 말들이 오고 갔지만 큰 꿈일수록 깨지는 조각도 크듯 상위 5% 안에 들자는 목표를 세웠습니다.
분석 처음부터 24gigabyte가 넘는 데이터 크기로 인해 로컬 환경에 불러오기조차 하지 못하였습니다. 저는 이 문제를 해결하기 위해 분석 가능한 환경을 찾던 중 가상환경인 AWS의 클라우드 서비스를 통해 해결 가능하단 것을 알게 되어 분석을 시작했습니다.
그리고 5,120개의 column이 오히려 모델의 정확도를 떨어뜨리는 점을 발견하여 통계지식을 활용한 feature engineering을 통해 정확도를 올리고자 매일 점심 직후 40분간 ‘데이터 과학을 위한 통계’ 책을 가지고 팀원들과 학습을 진행하여 분석 역량과 모델의 정확도를 함께 발전시켜나갔습니다.
그 결과 첫 대회에서 1,030팀 중 26위를 달성하여 목표보다 더 높은 성과를 낸 뜻깊은 경험이었습니다.

```