{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression을 그림으로 알아보자!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 값은 2.863301992416382\n",
      "Cost 값은 0.27753087878227234\n",
      "Cost 값은 0.2631648778915405\n",
      "Cost 값은 0.2581658661365509\n",
      "Cost 값은 0.2558729350566864\n",
      "Cost 값은 0.2545683681964874\n",
      "Cost 값은 0.2536725699901581\n",
      "Cost 값은 0.25295934081077576\n",
      "Cost 값은 0.25233232975006104\n",
      "Cost 값은 0.25174811482429504\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(action=\"ignore\") # warning출력을 배제\n",
    "\n",
    "x, y = mglearn.datasets.make_forge()\n",
    "\n",
    "# 먼저 간단하게 산점도(scatter)를 그려 보자.\n",
    "\n",
    "# y값이 0인 x를 추출해서 x의 첫번째 컬럼을 x축으로, \n",
    "# x의 두번째 컬럼을 y축으로 산점도를 그려보자.\n",
    "blue = x[y == 0]\n",
    "plt.scatter(blue[:,0],blue[:,1]) \n",
    "\n",
    "orange = x[y == 1]\n",
    "plt.scatter(orange[:,0],orange[:,1]) \n",
    "\n",
    "## machine learning (Logistic Regression)\n",
    "# train data set (연습용이니 test data set은 넘어가자.)\n",
    "train_x_data = x\n",
    "train_y_data = y.reshape(-1,1)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# Cost(loss) function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                                 labels = Y))\n",
    "\n",
    "# train node\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost) # 굳이 optimizer 만들지 않고 여기 opt에 넣어서 축약하자!\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = { X : train_x_data,\n",
    "                                                          Y : train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(f\"Cost 값은 {cost_val}\")\n",
    "        \n",
    "        \n",
    "# 정확도 측정(Accuracy)\n",
    "# skip : if 95% 이상 나오면 쓸만한 model\n",
    "\n",
    "# Prediction(예측)\n",
    "result = sess.run(H, feed_dict={ X : [[9,4]]})\n",
    "result # 결과값 : 0.834....\n",
    "\n",
    "plt.scatter(9,4)\n",
    "\n",
    "# sklearn 모델생성\n",
    "model = LogisticRegression()\n",
    "myModel = model.fit(x,y) # logistic model 학습\n",
    "print(myModel.predict([[9,4]])) # 결과값 : [1]\n",
    "mglearn.plots.plot_2d_separator(myModel, x, fill=False, \n",
    "                                eps=0.5, alpha=0.7) \n",
    "\n",
    "# 1과 0을 나누는 기준을 (선)을 긋는다. # Hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d535929b00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic을 multinomial로 확장해 보자!\n",
    "# x쪽 데이터는 시험성적과 출석점수 \n",
    "# y쪽 데이터는 학점\n",
    "x = np.array([[10, 5],\n",
    "               [9, 5],\n",
    "               [5, 1],\n",
    "               [4, 2],\n",
    "               [1, 3]])\n",
    "\n",
    "y = np.array([[\"A\"],\n",
    "              [\"A\"],\n",
    "              [\"B\"],\n",
    "              [\"B\"],\n",
    "              [\"C\"]])\n",
    "\n",
    "plt.scatter(x[0:2, 0],x[0:2, 1]) # A등급의 점을 찍어보자.\n",
    "plt.scatter(x[2:4, 0],x[2:4, 1]) # B등급의 점을 찍어보자.\n",
    "plt.scatter(x[4, 0],x[4, 1]) # C등급의 점을 찍어보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 값 : 8.066079139709473\n",
      "Cost 값 : 1.849338412284851\n",
      "Cost 값 : 1.371898889541626\n",
      "Cost 값 : 1.095597505569458\n",
      "Cost 값 : 0.8455120325088501\n",
      "Cost 값 : 0.5786193609237671\n",
      "Cost 값 : 0.05026910826563835\n",
      "Cost 값 : 0.04567387327551842\n",
      "Cost 값 : 0.042345963418483734\n",
      "Cost 값 : 0.0396796278655529\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# one-hot encoding\n",
    "# Y label을 string으로 표현할 수 없으니 이런 표현방법을 통해 Y label 만들어 준다!\n",
    "# 고양이\t강아지\t호랑이\n",
    "# 0 \t 1  \t0\n",
    "# 1 \t 0  \t0\n",
    "# 0 \t 0  \t1\n",
    "\n",
    "\n",
    "# train data set\n",
    "train_x_data = [[10,7,8,5],\n",
    "                [8,8,9,4],\n",
    "                [7,8,2,3],\n",
    "                [6,3,9,3],\n",
    "                [7,5,7,4],\n",
    "                [3,5,6,2],\n",
    "                [2,4,3,1]]\n",
    "\n",
    "train_y_data = [[1,0,0],\n",
    "                [1,0,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,1,0],\n",
    "                [0,0,1],\n",
    "                [0,0,1]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([4,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit) # sigmoid 에서 softmax로 변경!!!!!\n",
    "\n",
    "# Cost(loss) Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                    labels=Y))\n",
    "\n",
    "# train node\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={ X : train_x_data,\n",
    "                                                        Y : train_y_data})\n",
    "    if step % 300 == 0:\n",
    "        print(f\"Cost 값 : {cost_val}\")\n",
    "\n",
    "# Accuracy (정확도)\n",
    "# sess.run(H, feed_dict = { X : [[10,8,9,5]]}) # 임의값으로 예측결과 확인해보기\n",
    "# array([[9.9095786e-01, 9.0419911e-03, 6.2689011e-08]], dtype=float32)\n",
    "\n",
    "predict = tf.argmax(H, axis=1) # 가장 큰값의 index번호를 리턴\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis=1))\n",
    "\n",
    "# sample 데이터여서 기존의 결과로 정홛도를 확인 => 1.0 나오는게 당연!\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict = { X : train_x_data,\n",
    "                                                           Y : train_y_data})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI 데이터를 학습한 후 자신의 키와 몸무게를 넣어서 확인헤보자.\n",
    "## 상태를 확인하기 위해 bmi.csv 파일 가져와서 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost 값 : 1.2941728830337524\n",
      "Cost 값 : 0.3616917133331299\n",
      "Cost 값 : 0.2839779853820801\n",
      "Cost 값 : 0.24556522071361542\n",
      "Cost 값 : 0.22129392623901367\n",
      "Cost 값 : 0.20408686995506287\n",
      "Cost 값 : 0.1910295933485031\n",
      "Cost 값 : 0.18066242337226868\n",
      "Cost 값 : 0.17216189205646515\n",
      "Cost 값 : 0.16501976549625397\n"
     ]
    }
   ],
   "source": [
    "bmi = pd.read_csv(\"./data/bmi.csv\", skiprows=3)\n",
    "bmi.head()\n",
    "bmi.tail()\n",
    "\n",
    "# train data set 범위\n",
    "bmi.shape\n",
    "bmi_num = int(bmi.shape[0] * 0.8)\n",
    "bmi_num    \n",
    "\n",
    "# label을 one hot encoding 변환\n",
    "# numpy 이용\n",
    "# Y_lab = np.unique(bmi[\"label\"], axis=0)\n",
    "# y_data=np.eye(Y_lab.shape[0])[bmi[\"label\"]]\n",
    "# train_y_data=y_data[bmi_num:]\n",
    "\n",
    "# pandas.get_dummies()\n",
    "# y_data = pd.get_dummies(bmi[\"label\"])\n",
    "\n",
    "# tensorflow.one_hot()\n",
    "y_data = tf.one_hot(bmi[\"label\"], 3)\n",
    "sess = tf.Session()\n",
    "y_data = sess.run(y_data)\n",
    "\n",
    "\n",
    "# minmaxscaler 이용하기\n",
    "scl = MinMaxScaler()\n",
    "scl.fit(bmi[[\"height\",\"weight\"]])\n",
    "\n",
    "\n",
    "# train data set\n",
    "train_x_data = scl.fit_transform(bmi[[\"height\",\"weight\"]])[:bmi_num]\n",
    "train_y_data = y_data[:bmi_num]\n",
    "\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,3]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                    labels = Y))\n",
    "\n",
    "# train node 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "\n",
    "# session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={ X : train_x_data,\n",
    "                                                        Y : train_y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(f\"Cost 값 : {cost_val}\")\n",
    "        \n",
    "# test data set 만들기\n",
    "test_x_data = MinMaxScaler().fit_transform(bmi[[\"height\",\"weight\"]])[bmi_num:]\n",
    "test_y_data = y_data[bmi_num:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9797499775886536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 측정\n",
    "\n",
    "predict = tf.argmax(H, axis=1) # 가장 큰값의 index번호를 리턴\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                        Y:test_y_data})))\n",
    "# 나의 정보 확인\n",
    "myinfo = scl.transform([[181,75]])\n",
    "sess.run(tf.argmax(H, axis=1), feed_dict={X : myinfo})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "180 55\n",
      "너무마르셨네요.\n",
      "171 55\n",
      "보기 좋습니다.\n",
      "190 55\n",
      "너무마르셨네요.\n"
     ]
    }
   ],
   "source": [
    "T = int(input())\n",
    "for _ in range(T):\n",
    "    a = list(map(int, input().split()))\n",
    "    scl.fit(bmi[[\"height\",\"weight\"]])\n",
    "    myinfo = scl.transform([a])\n",
    "    check_body = sess.run(tf.argmax(H, axis=1), feed_dict={X : myinfo})\n",
    "\n",
    "    if check_body[0] == 0:\n",
    "        print(\"너무마르셨네요.\")\n",
    "    elif check_body[0] == 1:\n",
    "        print(\"보기 좋습니다.\")\n",
    "    else:\n",
    "        print(\"이럴시간이 없습니다.운동하세요 덜먹으시던가\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "180 55\n",
      "너무마르셨네요.\n",
      "171 66\n",
      "보기 좋습니다.\n",
      "191 100\n",
      "이럴시간이 없습니다.운동하세요 덜먹으시던가\n"
     ]
    }
   ],
   "source": [
    "T = int(input())\n",
    "for _ in range(T):\n",
    "    q, p = map(int, input().split())\n",
    "    scl.fit(bmi[[\"height\",\"weight\"]])\n",
    "    myinfo = scl.transform([[q,p]])\n",
    "    check_body = sess.run(tf.argmax(H, axis=1), feed_dict={X : myinfo})\n",
    "\n",
    "    if check_body[0] == 0:\n",
    "        print(\"너무마르셨네요.\")\n",
    "    elif check_body[0] == 1:\n",
    "        print(\"보기 좋습니다.\")\n",
    "    else:\n",
    "        print(\"이럴시간이 없습니다.운동하세요 덜먹으시던가\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
