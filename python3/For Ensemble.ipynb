{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 module import\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data Loading\n",
    "\n",
    "k_train_mnist = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "k_test_mnist = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(k_train_mnist)\n",
    "\n",
    "x_data = scaler.fit_transform(k_train_mnist.iloc[:,1:])\n",
    "y_data = pd.get_dummies(k_train_mnist[\"label\"]).values\n",
    "\n",
    "pre_x_data = scaler.fit_transform(k_test_mnist.values)\n",
    "\n",
    "\n",
    "# train / test 구분\n",
    "train_num = int(x_data.shape[0] * 0.8)\n",
    "\n",
    "# train data set\n",
    "train_x_data = x_data[:train_num]\n",
    "train_y_data = y_data[:train_num]\n",
    "\n",
    "# test data set\n",
    "test_x_data = x_data[train_num:]\n",
    "test_y_data = y_data[train_num:]\n",
    "\n",
    "# 함수로 모델 1개 만드는 로직 짜기\n",
    "\n",
    "\n",
    "result = []\n",
    "def make_H(X,Y,d_rate):\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "    d_rate = tf.placeholder(dtype=tf.float32)\n",
    "    \n",
    "    x_img = tf.reshape(X, [-1,28,28,1])\n",
    "    L1 = tf.layers.conv2d(inputs=x_img, filters=32,\n",
    "                             kernel_size=[3,3], strides=1,\n",
    "                             padding=\"SAME\", activation=tf.nn.relu)\n",
    "    L1 = tf.layers.max_pooling2d(inputs=L1, pool_size = [2,2],\n",
    "                                   padding=\"SAME\", strides=2)\n",
    "    L1 = tf.layers.dropout(inputs=L1, rate=d_rate)\n",
    "    \n",
    "    L2 = tf.layers.conv2d(inputs=L1, filters=64,\n",
    "                             kernel_size=[3,3], strides=1,\n",
    "                             padding=\"SAME\", activation=tf.nn.relu)\n",
    "    L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2],\n",
    "                                    padding=\"SAME\", strides=2)\n",
    "    L2 = tf.layers.dropout(inputs=L2, rate=d_rate)\n",
    "    \n",
    "    Dl3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "    \n",
    "    Dl3 = tf.layers.dense(inputs=Dl3, units=256, activation=tf.nn.relu)\n",
    "    \n",
    "    Dl4 = tf.layers.dense(inputs=Dl3, units=128, activation=tf.nn.relu)\n",
    "    \n",
    "    Dl5 = tf.layers.dense(inputs=Dl4, units=512, activation=tf.nn.relu)\n",
    "    \n",
    "    H = tf.layers.dense(inputs=Dl5, units=10)\n",
    "    \n",
    "    cost = tf.losses.softmax_cross_entropy(Y, H) # 순서가 바뀐다\n",
    "\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    train_epoch = 30\n",
    "    batch_size = 100\n",
    "\n",
    "    for step in range(train_epoch):\n",
    "        num_of_iter = int(train_x_data.shape[0]/batch_size)\n",
    "        cost_val = 0\n",
    "        for i in range(num_of_iter):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            cut_train_x = train_x_data[start:end]\n",
    "            cut_train_y = train_y_data[start:end]\n",
    "            _, cost_val = sess.run([train, cost], \n",
    "                                   feed_dict={ X : cut_train_x,\n",
    "                                                Y : cut_train_y,\n",
    "                                                 d_rate : 0.8})\n",
    "\n",
    "        if step % 3 == 0:\n",
    "            print(\"Cost값 : {}\".format(cost_val))\n",
    "\n",
    "     \n",
    "        result.append(list(sess.run(H, feed_dict={X : test_x_data}))[0])\n",
    "        result_H = result\n",
    "            \n",
    "    return result_H\n",
    "\n",
    "\n",
    "for _ in range(2):\n",
    "    a=make_H(train_x_data, train_y_data, 0.2)\n",
    "    print(a)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
